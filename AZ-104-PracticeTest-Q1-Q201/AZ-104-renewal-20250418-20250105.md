
# AZ-104-renewal-20250418-20250105

[AZ-104-renewal-20250418](https://learn.microsoft.com/en-us/collections/86mpuokngry47x)  

[AZ-104-renewal-20250418-20250105-material](https://learn.microsoft.com/en-us/collections/g23msm051x40y6)  

# Modules

[Host a web application with Azure App Service](https://learn.microsoft.com/en-us/training/modules/host-a-web-app-with-azure-app-service/)  

[Secure your Azure Storage account](https://learn.microsoft.com/en-us/training/modules/secure-azure-storage-account/?ns-enrollment-type=Collection&ns-enrollment-id=86mpuokngry47x)  

[Secure and isolate access to Azure resources by using network security groups and service endpoints](https://learn.microsoft.com/en-us/training/modules/secure-and-isolate-with-nsg-and-service-endpoints/)    

[Protect your virtual machines by using Azure Backup](https://learn.microsoft.com/en-us/training/modules/protect-virtual-machines-with-azure-backup/)  

[Configure virtual machine availability](https://learn.microsoft.com/en-us/training/modules/configure-virtual-machine-availability/)   

[Manage users and groups in Microsoft Entra ID](https://learn.microsoft.com/en-us/training/modules/manage-users-and-groups-in-aad/)  

---

# Assessment date: February 17, 2025

26 questions from 60 to 86

---

## Q08x:

---

## Answer:

---

## Reference:

---

## Q084 = ## Q026 = Q58 
## Q083 = ## Q057 
## Q082 = ## Q022 
## Q081 = ## Q056 

---

## Q080:

You have an Azure subscription named Sub1.

You plan to deploy a virtual machine scale set named VMSS1 in East US region. VMSS1 will have 8 instances.

What is the maximum number of availability zones that VMSS1 can use?

Select only one answer.

1
2
3
4

---

## Answer 1:

Correct Answer:
3

Explanation:
Azure Virtual Machine Scale Sets (VMSS) support up to 3 availability zones in regions that offer zone redundancy (like East US).

Key Facts About VMSS and Availability Zones:
VMSS can distribute instances across multiple availability zones (up to 3 zones in supported regions).
This provides high availability and resiliency by ensuring instances are spread across physically separate datacenters.
If a region supports Availability Zones, a VMSS can use up to 3 zones for better fault tolerance.
Why Not the Other Options?

Option	Reason It’s Incorrect
1	You can deploy VMSS in only one zone, but that doesn’t maximize availability.
2 	Some workloads may use 2 zones, but VMSS supports up to 3 zones for better resilience.
4 	Azure only supports up to 3 zones, so 4 is not possible.

Conclusion:
Since East US supports availability zones, and VMSS can use up to 3 zones, the correct answer is:
3.

---

> is it true that the maximum number of availability zones supported by a virtual machine scale set is 3?

Yes, it is true! 
Azure Virtual Machine Scale Sets (VMSS) support up to 3 Availability Zones.
In regions that support Availability Zones, VMSS can distribute instances across a maximum of three zones. This ensures high availability by placing instances in physically separate datacenters.

Key Points:
Max availability zones for VMSS: 3
Regions must support Availability Zones (e.g., East US, West Europe, etc.).

[Deploy virtual machine scale set instances using availability zones](https://azure.github.io/PSRule.Rules.Azure/en/rules/Azure.VMSS.AvailabilityZone/)  


---

## Reference:

[Expand scale set to use availability zones](https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-availability-zones?tabs=portal-2#expand-scale-set-to-use-availability-zones)    

You can update the scale set to scale out instances to one or more additional availability zones, 
up to the number of availability zones supported by the region. 
For regions that support zones, the minimum number of zones is 3.

[Create a Virtual Machine Scale Set that uses Availability Zones](https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-availability-zones?tabs=portal-2)   

---

## Q079 = ## Q054 = Q023 

---

## Q078:

You have a Recovery Services vault named Vault1 that has soft delete enabled.

Vault1 stores backups for the following Azure resources:

- an Azure virtual machine named VM1
- an Azure file share named share1
- a SQL Server on Azure virtual machine named SQL1

Which backups are protected by soft delete?

Select only one answer.

- share1 only
- VM1 and SQL1 only
- VM1 only
- VM1, share1, and SQL1

---

## Answer:

Correct Answer:
VM1 and SQL1 only

Explanation:
Soft delete in Azure Backup helps protect against accidental or malicious deletions by keeping backup data for 14 additional days after deletion.

Soft Delete Protection Applies To:

Azure Virtual Machines (VM1) 
SQL Server on Azure Virtual Machines (SQL1) 

Soft Delete Does NOT Apply To:
Azure File Shares (share1) 

Soft delete for Azure File Shares is managed at the storage account level, not through the Recovery Services Vault.
If file share backups are deleted, they are permanently lost unless soft delete is enabled in the storage account.

Why Not the Other Options?

"share1 only" 
Incorrect, because soft delete for file shares is not controlled by the Recovery Services Vault.

"VM1 only" 
Incorrect, because SQL Server backups are also protected by soft delete.

"VM1, share1, and SQL1" 
Incorrect, because soft delete does not apply to Azure File Shares in the Recovery Services Vault.

> Conclusion:
VM1 and SQL1 backups are protected by soft delete in Vault1.

---

## Reference:

[Soft delete for Azure Backup](https://learn.microsoft.com/en-us/azure/backup/backup-azure-security-feature-cloud?tabs=azure-portal)    

It's important to remember that once soft delete is disabled, the feature is disabled for all the types of workloads. For example, it's not possible to disable soft delete only for SQL server or SAP HANA DBs while keeping it enabled for virtual machines in the same vault. You can create separate vaults for granular control.

> Soft delete protection is available for these services:

- [Soft delete for Azure virtual machines](https://learn.microsoft.com/en-us/azure/backup/soft-delete-virtual-machines)  
- [Soft delete for SQL server in Azure VM and soft delete for SAP HANA in Azure VM workloads](https://learn.microsoft.com/en-us/azure/backup/soft-delete-sql-saphana-in-azure-vm?tabs=azure-portal)  

[Frequently asked questions - Protect backups from Ransomware](https://learn.microsoft.com/en-us/azure/backup/protect-backups-from-ransomware-faq)  

Soft delete is enabled by default on a newly created Recovery Services vault. It protects backup data from accidental or malicious deletes for 14 days at no additional cost, allowing the recovery of that backup item before it’s permanently lost. We recommend not to disable this feature. If backups are deleted and soft delete isn’t enabled, you or Microsoft can’t recover the deleted backup data. Use Multi-user authorization (MUA) as an additional layer of protection for these critical operations on your Recovery Services vault to validate operation before disabling this feature. For more information, see How to enable, manage, and when to disable soft delete for Azure Backup?

[Use soft delete to prevent accidental deletion of Azure file shares](https://learn.microsoft.com/en-us/azure/storage/files/storage-files-prevent-file-share-deletion)  

Azure Files offers soft delete, which allows you to recover your file share when it's mistakenly deleted by an application or other storage account user.

> Enabling or disabling soft delete

Soft delete for file shares is enabled at the storage account level. 

Because of this, the soft delete settings apply to all file shares within a storage account. Soft delete is enabled by default for new storage accounts and can be disabled or enabled at any time. Soft delete isn't automatically enabled for existing storage accounts unless Azure file share backup is configured for a Azure file share in that storage account. If Azure file share backup is configured, then soft delete for Azure file shares are automatically enabled on that share's storage account.

If you delete some file shares with soft delete enabled and then disable soft delete, you can still access and recover those file shares as long as they were saved during the period when soft delete was enabled.

[Back up Azure File shares](https://learn.microsoft.com/en-us/azure/backup/backup-azure-files?tabs=recovery-services-vault#create-a-recovery-services-vault)   

---

## Q077 = ## Q050 = ## Q018
## Q076 = ## Q017

---

## Q075:

You have an Azure subscription that contains the following virtual machines:

- VM1, a virtual machine that runs Windows Server 2019
- VM2, a virtual machine that runs Red Hat Enterprise Linux
- VM3, a virtual machine that is configured with Azure Disk encryption and runs Windows Server 2022

You use Azure Backup to back up the three virtual machines.

Which virtual machine or virtual machines can use file-level restore?

Select only one answer.

- VM1 and VM2 only
- VM1 and VM3 only
- VM1 only
- VM1, VM2 and VM3

---

## Answer 1:

VM1 and VM2 only can use file-level restore.

File-level restore from Azure Backup is supported for Windows VMs (like VM1) and Linux VMs (like VM2) as long as they are not encrypted at the disk level.  
VM3 is encrypted with Azure Disk Encryption, which prevents file-level restores.  
Therefore, only VM1 and VM2 support this functionality.

---

## Answer 2:

Correct Answer:
VM1 and VM2 only

Explanation:
Azure Backup supports file-level restore (also known as Item-level restore) for:

Windows Virtual Machines
Linux Virtual Machines
However, file-level restore is NOT supported for Azure Disk Encryption (ADE)-enabled VMs.

Analyzing the Virtual Machines:

VM	OS	                        Azure Disk Encryption (ADE)?	Supports File-Level Restore?
VM1	Windows Server 2019 	    No	                                Yes
VM2	Red Hat Enterprise Linux 	No	                                Yes
VM3	Windows Server 2022 	    Yes (Encrypted)	                    No

Why VM3 Cannot Use File-Level Restore:
Azure Backup does NOT support file-level restore for encrypted VMs (with Azure Disk Encryption - ADE).

The only option for VM3 is restoring the entire VM or disk instead of individual files.

Conclusion: VM1 and VM2 can use file-level restore, but VM3 cannot.
Thus, the correct answer is: VM1 and VM2 only.

---

## Reference:

[Restore encrypted Azure virtual machines](https://learn.microsoft.com/en-us/azure/backup/restore-azure-encrypted-virtual-machines)  

This article describes how to restore Windows or Linux Azure virtual machines (VMs) with encrypted disks using the Azure Backup service. For more information, see Encryption of Azure VM backups.

ADE encrypted VMs can’t be recovered at the file/folder level. 
You need to recover the entire VM to restore files and folders.

---

## Q074 = ## Q013 = ## Q048
## Q073 = ## Q014

---

## Q072:

You have an Azure subscription that contains the following virtual networks:

- VNet1, located in the West US region. 3 virtual machines are connected to VNet1.
- VNet2, located in the West US region. 4 virtual machines are connected to VNet2.
- VNet3, located in the East US region, 5 virtual machines are connected to VNet3.
- VNet4, located in the East US region, 2 virtual machines are connected to VNet4.

Every virtual network is peered with all other virtual networks.

You plan to protect all of the connected virtual machines by using Azure Bastion.

What is the minimum number of Azure Bastion hosts that you must deploy?

Select only one answer.

1
2
3
4

---

## Answer 3:
1
> Every virtual network is peered with all other virtual networks.

[EXAM AZ-104 TOPIC](https://www.examtopics.com/discussions/microsoft/view/119641-exam-az-104-topic-5-question-136-discussion/)  

You have an Azure subscription that contains the virtual networks shown in the following table.
...

All the virtual networks are peered. Each virtual network contains nine virtual machines.

You need to configure secure RDP connections to the virtual machines by using Azure Bastion.

What is the minimum number of Bastion hosts required?

A. 1
B. 3
C. 9
D. 10

Answer is A.
We required only one Bastion.
https://learn.microsoft.com/en-us/azure/bastion/vnet-peering

Azure Bastion works with the following types of peering:

Virtual network peering: Connect virtual networks within the same Azure region.
Global virtual network peering: Connecting virtual networks across Azure regions.

---

## Answer 1:

Correct Answer:
2

Explanation:
Azure Bastion is a fully managed jump-box service that allows secure RDP/SSH access to virtual machines without exposing public IPs.

Key Considerations for Bastion Deployment:
Bastion is deployed at the Virtual Network (VNet) level.
A single Bastion host can provide access to all VMs within its VNet and any peered VNets in the same region.
Bastion does not work across regions, meaning you need at least one Bastion per region.

VNet Configuration and Required Bastion Hosts:

Region	VNets	Peering	Required Bastion?
West US	VNet1, VNet2 Peered together One Bastion needed
East US	VNet3, VNet4 Peered together One Bastion needed

Since VNets in West US are peered together, one Bastion can serve both VNet1 and VNet2.
Similarly, VNets in East US are peered together, so one Bastion can serve both VNet3 and VNet4.

Thus, the minimum number of Bastion hosts required is 2 (one per region).


## Answer 2:

You need a minimum of 2 Azure Bastion hosts.

Azure Bastion is deployed on a per-virtual-network basis.  Since you have four virtual networks across two regions, you need one Bastion host in each region.  Peering the virtual networks does not eliminate the need for Bastion in each VNet.  You can use a single Bastion host to access all VMs in the VNet it's deployed in, but you can't use one Bastion host across different VNets, even if they're peered. Therefore, you need one in West US (to cover VNet1 and VNet2) and one in East US (to cover VNet3 and VNet4).

---

## Reference:

[Can I still deploy multiple Bastion hosts across peered virtual networks?](https://docs.azure.cn/en-us/bastion/bastion-faq)  

Yes. By default, a user sees the Bastion host that is deployed in the same virtual network in which VM resides. However, in the Connect menu, a user can see multiple Bastion hosts detected across peered networks. They can select the Bastion host that they prefer to use to connect to the VM deployed in the virtual network.

[If my peered VNets are deployed in different subscriptions, will connectivity via Bastion work?](https://docs.azure.cn/en-us/bastion/bastion-faq#if-my-peered-vnets-are-deployed-in-different-subscriptions-will-connectivity-via-bastion-work)  

Yes, connectivity via Bastion will continue to work for peered virtual networks across different subscription for a single Tenant. Subscriptions across two different Tenants aren't supported. To see Bastion in the Connect drop down menu, the user must select the subs they have access to in Subscription > global subscription.

---

[How to connect virtual networks across Azure regions with Azure Global VNet peering](https://learn.microsoft.com/en-us/shows/azure-friday/how-to-connect-virtual-networks-across-azure-regions-with-azure-global-vnet-peering)  

---

[Azure Bastion for accessing VM's in different VNET](https://learn.microsoft.com/en-us/answers/questions/1306235/azure-bastion-for-accessing-vms-in-different-vnet)  

If you have VMs in different VNets and want to access them using Azure Bastion, you would need to deploy separate Azure Bastion instances in each VNet. Each Azure Bastion instance will provide access only to the VMs within the same VNet where it is deployed.

However, if you require centralized access to VMs across multiple VNets, you may consider alternative solutions such as establishing VPN or VNet peering between the VNets to enable connectivity between them. This way, you can connect to the VMs in different VNets using a single VPN gateway or virtual network gateway.

---

[Virtual network peering and Azure Bastion](https://learn.microsoft.com/en-us/azure/bastion/vnet-peering)    

Azure Bastion and Virtual Network peering can be used together. When Virtual Network peering is configured, you don't have to deploy Azure Bastion in each peered VNet (virtual network). This means if you have an Azure Bastion host configured in one virtual network, it can be used to connect to virtual machines (VMs) deployed in a peered virtual network without deploying an additional bastion host. 


Azure Bastion works with the following types of peering:

- Virtual network peering: Connect virtual networks within the same Azure region.
- Global virtual network peering: Connecting virtual networks across Azure regions.

- Deploying Azure Bastion within a Virtual WAN hub is not supported. 
You can deploy Azure Bastion in a spoke VNet and use the IP-based connection feature 
to connect to virtual machines deployed across a different VNet via the Virtual WAN hub.

---

[Peering between two vnets in different subscription and region](https://learn.microsoft.com/en-us/answers/questions/1346188/peering-between-two-vnets-in-different-subscriptio)   

You can Global virtual network peering to achieve this. 
You set this up the same way as standard peering,
but it will allow you to peer networks in different regions. 

 Just bear in mind there are constraints.

Resources in one virtual network can't communicate with the front-end IP address of 
a Basic Load Balancer (internal or public) in a globally peered virtual network.

Some services that use a Basic load balancer don't work over global virtual network peering. 

[What are the constraints related to global virtual network peering and load balancers?](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-faq#what-are-the-constraints-related-to-global-virtual-network-peering-and-load-balancers)  

If the two virtual networks in two regions are peered over global virtual network peering, you can't connect 
to resources that are behind a basic load balancer through the front-end IP of the load balancer. 
This restriction doesn't exist for a standard load balancer.

The following resources can use basic load balancers, which means you can't reach them through 
a load balancer's front-end IP over global virtual network peering. 
But you can use global virtual network peering to reach the resources directly through their 
private virtual network IPs, if permitted.

VMs behind basic load balancers
Virtual machine scale sets with basic load balancers
Azure Cache for Redis
Azure Application Gateway v1
Azure Service Fabric
Azure API Management stv1
Microsoft Entra Domain Services
Azure Logic Apps
Azure HDInsight
Azure Batch
App Service Environment v1 and v2

You can connect to these resources via Azure ExpressRoute or network-to-network connections through virtual network gateways.

---

## Q071:

You have an Azure subscription that includes the following resources:

- VNet1, a virtual network
- Subnet1, a subnet in VNet1
- WebApp1, a web app application service
- NSG1, a network security group

You create an application security group named ASG1.

Which resource can use ASG1?

Select only one answer.

- NSG1
- Subnet1
- VNet1
- WebApp1

---

## Answer:

Correct Answer:
NSG1

Explanation:
An Application Security Group (ASG) is used to group virtual machines (VMs) 
for easier network security management in Network Security Groups (NSGs).

NSG1 (Network Security Group) Allowed

ASGs are used in NSG security rules to apply rules to a group of VMs instead of using IP addresses.
Subnet1 (Subnet in VNet1) Not Allowed

ASGs are not assigned to subnets, only to VMs or NICs.
VNet1 (Virtual Network) Not Allowed

ASGs do not apply at the VNet level; they are used within NSGs.
WebApp1 (Web App Service) Not Allowed

ASGs are designed for Virtual Machines (VMs) and NICs, not for App Services (Web Apps).

---

## Reference:

---

## Q070 = ## Q043
## Q069 = ## Q009
## Q068 = ## Q041
## Q067 = ## Q008
## Q066 = ## Q039

---

## Q065:

You have an Azure subscription that contains the following resources:

a storage account named storage123
a container instance named container1

The subscription contains a virtual network named VirtualNet4 that has the following subnets:

SubnetA- has a Microsoft.Storage service endpoint.
SubnetB- container1 is deployed to SubnetB.
SubnetC- No resources are connected to SubnetC.

You plan to deploy an Azure container instance named container5 to VirtualNet4.

To which subnets can you deploy container5?

Select only one answer.

- SubnetA, SubnetB, and SubnetC
- SubnetB and SubnetC only
- SubnetB only
- SubnetC only

---

## Answer 1:
- SubnetA, SubnetB, and SubnetC < BETTER?

Answer: SubnetB and SubnetC only < NO

Explanation:
Azure Container Instances (ACI) require a subnet without service endpoints for other services like Microsoft.Storage. 
Since SubnetA has a Microsoft.Storage service endpoint, it cannot host a container instance.

SubnetA Not Allowed (Has a Microsoft.Storage service endpoint, which prevents ACI deployment)
SubnetB Allowed (Already hosting container1, so it supports ACI)
SubnetC Allowed (No restrictions, so it supports ACI)

Thus, container5 can only be deployed to SubnetB or SubnetC.

## Answer 2:

You can deploy container5 to SubnetC only.

Here's why:

SubnetA: 
While SubnetA has a Microsoft.Storage service endpoint, this endpoint is for accessing storage from resources within the subnet. 
It doesn't enable deploying into the subnet. Container instances don't use storage service endpoints for deployment.

SubnetB: 
SubnetB already has container1 deployed to it. 
You cannot deploy multiple container instances to the same subnet unless they are part of the same container group.

SubnetC: 
SubnetC is empty and has no restrictions. 
Therefore, it's the only viable option for deploying container5.

---

## Reference:

---

`is it true that Azure Container Instances (ACI) require a subnet without service endpoints?`

ChatGPT said:
No, Azure Container Instances (ACI) do support subnets with service endpoints. 

However, there are specific considerations:

ACI can be deployed into subnets with service endpoints (e.g., Microsoft.Storage), 
but ACI itself does not use those endpoints to connect to services like Azure Storage.

If your ACI needs to access an Azure Storage account with network restrictions, you must 
use a private endpoint, managed identity, or firewall rules, because ACI does not inherit 
the service endpoint access from the subnet.

Corrected Answer for Your Question: SubnetA, SubnetB, and SubnetC

SubnetA Allowed (Even though it has a Microsoft.Storage service endpoint, ACI can still be deployed here.)
SubnetB Allowed (Already hosting container1, so it supports ACI.)
SubnetC Allowed (No restrictions, so it supports ACI.)

Key Takeaway:
ACI can be deployed into a subnet with service endpoints, but it does not inherit access to services behind those endpoints. 
If ACI needs to connect to a restricted storage account, you must use private endpoints, managed identity, or allow ACI’s public IP.


---

[Azure Container Instance - dns and subnet in the same container](https://stackoverflow.com/questions/53783124/azure-container-instance-dns-and-subnet-in-the-same-container)  

Unfortunately, if you deploy the Azure Container Instances in the Subnet of a Vnet, then you cannot set the public IPs or DNS for it. Azure does not support it, at least now. Maybe it will be supported in the future. For more details, see Virtual network deployment limitations.

Container groups deployed to a virtual network do not currently support public IP addresses or DNS name labels.


---

[Container groups in Azure Container Instances](https://learn.microsoft.com/en-us/azure/container-instances/container-instances-container-groups)  

---

[Virtual network scenarios and resources](https://learn.microsoft.com/en-us/azure/container-instances/container-instances-virtual-network-concepts#network-profile)  
[Azure Container Instances - VNet - Template](https://github.com/Azure/azure-quickstart-templates/tree/master/quickstarts/microsoft.containerinstance/aci-vnet)
The following diagram depicts several container groups deployed to a subnet 
delegated to Azure Container Instances. Once you deploy one container group 
to a subnet, you can deploy more container groups to it by specifying the 
same network profile.

---

[Using same subnet for different groups in docker container](https://www.reddit.com/r/docker/comments/10vg9ub/using_same_subnet_for_different_groups_in_docker/)  
I'm trying to create different groups of containers that functionally never talk to each other, 
and I want all the containers to be under the same subnet. 
Is this possible? How can I do this?

It serves for the purpose of avoiding choosing in an ip range that will cause problem in the program.

> Reply:

AFAIK, you can't have the same subnet associated with more then one 'docker network'. 
If you want isolation between containers, you normally need them on separate docker networks.
Can you elaborate more about what kind of problems you are worried about?
Depending on what you are doing, and how you are doing it, you could pass the specific subnet
you want to the docker network create.

So if you needed everything be in a range of 10.0.2.1-10.0.2.254 you could do something like this to create docker networks are all subnets of 10.0.2.0/24.

[Deploy container instances into an Azure virtual network](https://learn.microsoft.com/en-us/azure/container-instances/container-instances-vnet)  

---

## Q064 = ## Q038

---

## Q063:

You plan to deploy an Azure web app that will have the following settings:

Name: WebApp1
Publish: Code
Runtime stack: Java 21
Operating system: Linux
Continuous deployment: Disable

You need to ensure that you can integrate WebApp1 with GitHub Actions.

Which setting should you modify?

Select only one answer.

- Continuous deployment
- Operating system
- Publish
- Runtime stack

---

## Answer:
- Continuous deployment

> Explanation-1

The setting to modify is Continuous deployment.

While the current setting is "Disable", you need to enable continuous deployment to integrate with GitHub Actions.  
The other settings (Operating system, Publish, Runtime stack) are relevant for the web app's functionality, but they 
don't directly control the integration with GitHub Actions.

> Explanation-2

To integrate WebApp1 with GitHub Actions, you need to enable Continuous Deployment.

Explanation:
Continuous deployment: Disabled in the current configuration. This must be enabled to allow integration with GitHub Actions.
Operating system: Linux is supported for GitHub Actions.
Publish: "Code" is appropriate for Java 21 on Linux.
Runtime stack:  Java 21 is supported for GitHub Actions.

Correct Answer: Continuous deployment

Reason: GitHub Actions requires continuous deployment to be enabled in Azure App Service.

---

## Reference:

---

## Q061 = ## Q035
## Q060 = ## Q034
see details below.

---

# Failed Assessment date: February 15, 2025

26 questions from 34 to 59

Because you scored lower in "Host a web application with Azure App Service":

Host a web application with Azure App Service
31 mins
Because you scored lower in "Build a containerized web application with Docker":

Build a containerized web application with Docker
57 mins
Because you scored lower in "Secure your Azure Storage account":

Secure your Azure Storage account
45 mins
Because you scored lower in "Secure and isolate access to Azure resources by using network security groups and service endpoints":

Secure and isolate access to Azure resources by using network security groups and service endpoints
43 mins
Because you scored lower in "Protect your virtual machines by using Azure Backup":

Protect your virtual machines by using Azure Backup
35 mins
Because you scored lower in "Configure virtual machine availability":

Configure virtual machine availability
34 mins
Because you scored lower in "Manage users and groups in Microsoft Entra ID":

Manage users and groups in Microsoft Entra ID
50 mins

---

## Q059:

You have a Microsoft Entra tenant.

You create a user named Admin1.

You need to ensure that Admin1 can perform following tasks:

- Assign licenses to Microsoft Entra groups
- Reset passwords of Microsoft Entra users

What Microsoft Entra role should you add to Admin1?

Select only one answer.

- Billing Administrator
- Helpdesk Administrator
- License Administrator
- User Administrator

---

## Answer:

- User Administrator

The User Administrator role has the necessary permissions to both assign licenses to groups and reset user passwords.  While other roles might cover one of these tasks, only User Administrator covers both.

---

## Reference:

---

## Q058:

You have a Microsoft Entra tenant that contains a user named User1 and a group named Group1.

You need to enable User1 the ability to add members to Group1. 
Your solution should minimize administrative effort.

What should you do?

Select only one answer.

- Add Group1 to new administrative unit and assign built-in Microsoft Entra role to User1
- Assign custom Microsoft Entra role to User1
- Modify Group1 owners
- Modify Group1 properties

---

## Answer:
- Modify Group1 owners

> Modify Group1 owners:  
In Microsoft Entra ID, Group Owners have significant permissions over the group, including adding and removing members, managing group settings, and even deleting the group in some cases.  Making User1 an Owner of Group1 directly grants the required permission to add members. This is simple and direct, likely minimizing administrative effort.

> Modify Group1 properties:  
"Modifying Group1 properties" is vague.  There aren't specific group properties that directly toggle on/off the ability for a user to add members (besides owner settings).  Group settings are more about group type, membership types, etc.  This option is less likely to be the direct and minimal effort solution.

> Add Group1 to new administrative unit and assign built-in Microsoft Entra role to User1:  
Administrative units are used to scope administrative permissions to a subset of users or groups. While this could work, it seems like overkill and adds administrative overhead to create an AU just for this single requirement. Also, it is not clear which built-in role would directly allow "adding members to a specific group".  Group Administrator role might be relevant, but it might grant more permissions than just managing members of Group1.

> Assign custom Microsoft Entra role to User1:  
Creating a custom role provides granular control. You could define a custom role that specifically grants the permission to manage members of groups.  This is more precise but involves the administrative effort of defining and assigning a custom role.  It might be more effort than needed for just this requirement.

Why Not the Other Options?
Option	Why It's Incorrect?

Add Group1 to a new administrative unit and assign a built-in Microsoft Entra role to User1 > Overly complex.
Administrative units are used for scoping role assignments, not for managing individual group membership.

Assign a custom Microsoft Entra role to User1 	Unnecessary effort. 
A built-in role isn’t needed just to manage group membership.

Modify Group1 properties
Group properties do not control membership permissions. 
Owners manage membership, not properties.

---

## Reference:

---

## Q057:

You have a Microsoft Entra tenant named contoso.com that contains a user named Ben Smith.

You configure a Password protection for contoso.com that includes the following Custom banned 
passwords settings:

Enforce custom list: Yes
Custom banned password list: Contoso
Which password can be used by Ben Smith?

Select only one answer.

- C0nt0s0123
- CONTOSO123
- Conto123so
- FgRs01

---

## Answer:

- FgRs01

Password protection with a custom banned list prevents users from using passwords that contain all or part of the banned word.  In this case, "Contoso" is banned.  All the options except "FgRs01" contain "Contoso" (case insensitive). Therefore, only "FgRs01" is an acceptable password. 1 

Explanation:
Since "Contoso" is in the Custom banned password list, any password that contains "Contoso" (in any variation) cannot be used.

Let's analyze each option:
Password	Allowed?	Reason
C0nt0s0123 	Not Allowed	Contains a variation of "Contoso" with character substitutions (0 for o).
CONTOSO123 	Not Allowed	Matches "Contoso" in uppercase.
Conto123so 	Not Allowed	Still includes parts of "Contoso" in an easily recognizable pattern.
FgRs01 Allowed	Does not contain "Contoso" or any variation of it.

---

## Reference:

[You have an Azure Active Directory (Azure AD) tenant named contoso.com that contains a user named Ben Smith. You configure a Password protection for contoso.com that includes the following Custom banned passwords](https://learn.microsoft.com/en-us/answers/questions/642069/you-have-an-azure-active-directory-(azure-ad)-tena)  


[Tutorial: Configure custom banned passwords for Microsoft Entra password protection](https://learn.microsoft.com/en-us/entra/identity/authentication/tutorial-configure-custom-password-protection)  

[Custom banned password list](https://learn.microsoft.com/en-us/entra/identity/authentication/concept-password-ban-bad#custom-banned-password-list)  

Some organizations want to improve security and add their own customizations on top of the global banned password list. To add your own entries, you can use the custom banned password list. Terms added to the custom banned password list should be focused on organizational-specific terms such as the following examples:

Brand names
Product names
Locations, such as company headquarters
Company-specific internal terms
Abbreviations that have specific company meaning
When terms are added to the custom banned password list, they're combined with the terms in the global banned password list. Password change or reset events are then validated against the combined set of these banned password lists.

 Note

The custom banned password list is limited to a maximum of 1,000 terms. It isn't designed for blocking extremely large lists of passwords.

To fully apply the benefits of the custom banned password list, first understand how are passwords evaluated before you add terms to the custom banned list. This approach lets you efficiently detect and block large numbers of weak

[How are passwords evaluated](https://learn.microsoft.com/en-us/entra/identity/authentication/concept-password-ban-bad#how-are-passwords-evaluated)  

When a user changes or resets their password, the new password is checked for strength and complexity by validating it against the combined list of terms from the global and custom banned password lists.

Even if a user's password contains a banned password, the password may be accepted if the overall password is otherwise strong enough. A newly configured password goes through the following steps to assess its overall strength to determine if it should be accepted or rejected.

---

## Q056:

You have an Azure subscription that contains the following resources:

- A resource group named RG1 in the West US region
- A resource group named RG2 in the Central US region
- A virtual network named VNet1 that is deployed to the West US region in RG1
- A virtual network named VNet2 that is deployed to the Central US region in RG1
- A virtual network named VNet3 that is deployed to the West US region in RG2

You need to deploy a virtual machine named VM1 to RG1 in the West US region.

To which virtual network or virtual networks can you connect VM1?

Select only one answer.

- VNet1 only
- VNet1 or VNet2 only
- VNet1 or VNet3 only
- VNet1, VNet2 or VNet3

---

## Answer 2:
- VNet1 or VNet3 only

> I do not think the RG playes any role when a VM is deployed, only the VNet region.

---

## Answer 2:

Correct Answer:
VNet1 or VNet3 only

Explanation:
When deploying a virtual machine (VM1) to RG1 in the West US region, it must be connected to a virtual network (VNet) in the same region (West US).

Virtual Network Locations:
VNet1  West US ( Can connect)
VNet2  Central US ( Cannot connect)
VNet3  West US (Can connect)

VNet2 is in Central US, which is a different region, so it cannot be directly used when deploying VM1 in West US.

Why Not the Other Options?
Option	Why It's Incorrect

VNet1 only Incorrect – VNet3 is also in West US and can be used.
VNet1 or VNet2 only Incorrect – VNet2 is in Central US, which cannot be used for a VM in West US.
VNet1, VNet2, or VNet3 Incorrect – VNet2 is in a different region (Central US), so it cannot be used.

Conclusion:
Since VNet1 and VNet3 are both in the West US region, the correct answer is:
VNet1 or VNet3 only.

---

## Answer 1:

VNet1 only

A virtual machine must reside in the same region and resource group as the virtual network it is being deployed to.  
VM1 is being deployed to RG1 in West US.  
Therefore, it can only connect to VNet1, which is also in RG1 and West US.  
VNet2 is in Central US, and VNet3 is in a different resource group (RG2), so neither is eligible.

---

## Reference:

[What if I select different region for VM than Virtual network?](https://stackoverflow.com/questions/68333439/what-if-i-select-different-region-for-vm-than-virtual-network)  

Let's assume, I created a new Virtual Network in the Brazil South region and create a new VM with the virtual network but in the South India region. What happens after it was created. Is there any additional cost incurred?
The VM in south India is configured with the same VNet.

> A resource can only be created in a virtual network that exists in the same region and subscription as the resource. 

[How to move VM to a new Virtual Network in Azure Portal](https://serverfault.com/questions/814209/how-to-move-vm-to-a-new-virtual-network-in-azure-portal)  

Moving VMs between different VNET is not supported. 
To move the VM to another VNET, the only solution for now is re-create the VM with the same vhd file.

---

## Q055:

You have an Azure subscription and an availability set named AS1 that has 5 update domains.
You deploy 27 virtual machines to AS1.

During a planned update, what is the minimum number of virtual machines that are available?

Select only one answer.

14
20
21
22
26

---

## Answer:

- 21

Here's why:

Update Domains: 
Availability sets use update domains to control when VMs are rebooted during planned maintenance.  
With 5 update domains, Azure updates VMs in batches, one update domain at a time.

Distribution:  
With 27 VMs and 5 update domains, the VMs are distributed as evenly as possible across the update domains.  
In this case, three update domains will have 6 VMs each, and two update domains will have 5 VMs each.

Minimum Available: 
During an update, one update domain is taken offline at a time.  
In the worst-case scenario, the update domain with 6 VMs is taken offline. 
This leaves 27 - 6 = 21 VMs still running.

---

## Reference:

---

## Q054:

You have an Azure subscription.

You plan to run a data warehouse in an Azure virtual machine named VM1.
You need to ensure that VM1 is optimized for running a data warehouse.

Which VM type should you use for VM1?

Select only one answer.

- Compute optimized (F-Series)
- General purpose (D-Series)
- High performance computing (H-Series)
- Memory optimized (M-Series)
- Storage optimized (Ls-Series)

---

## Answer 3:

> is is impossible to clearly decide between Memory optimized (M-Series) & Storage optimized (Ls-Series)

The Mbsv3 and Mbdsv3 series VMs are recommended for mission critical and data warehouse workloads

[Mbsv3 and Mbdsv3 series](https://learn.microsoft.com/en-us/azure/azure-sql/virtual-machines/windows/performance-guidelines-best-practices-vm-size?view=azuresql#mbsv3-and-mbdsv3-series)  

The Mbsv3 and Mbdsv3 series are memory optimized VMs designed for large in-memory databases and workloads with high memory-to-CPU ratio needs. The VMs in this series are built on the 4th generation Intel® Xeon® Scalable and offer a range of memory sizes and vCPU counts to meet the needs of your SQL Server workloads. The Mbsv3 and Mbdsv3 series VMs are recommended for mission critical and data warehouse workloads.

The Mbsv3 and Mbdsv3 series VMs support support large in-memory databases and workloads with a high memory-to-CPU ratio perfect for relational database servers, data warehousing, heavy reporting, large caches, and in-memory analytics.

['L' family storage optimized VM size series](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/storage-optimized/l-family)  

The 'L' family of VM size series are one of Azure's storage-optimized VM instances. They're designed for workloads that require high disk throughput and I/O, such as databases, big data applications, and data warehousing. Equipped with high disk throughput and large local disk storage capacities, L-series VMs support applications and services that benefit from low latency and high sequential read and write speeds. This makes them particularly well-suited for handling tasks like large-scale log processing, real-time big data analytics, and scenarios involving large databases that perform frequent disk operations, ensuring efficient performance for storage-heavy applications.

---

## Answer 1:

PT said:
Correct Answer:
Storage optimized (Ls-Series)

Explanation:
A data warehouse requires:

High disk throughput (fast read/write speeds).
Low-latency storage access for processing large datasets.
Optimized disk performance for handling heavy I/O workloads.

Why Choose Ls-Series?
Storage Optimized (Ls-Series) VMs are designed for:

High disk throughput & low latency storage (critical for data warehouses).
High-speed local SSD storage for fast data access.
Ideal for workloads with heavy disk I/O (like data warehousing and big data applications).

Why Not the Other Options?

VM Type	Reason It's NOT Suitable for Data Warehousing
F-Series (Compute Optimized)	Best for high CPU workloads, but lacks high storage throughput.
D-Series (General Purpose) 	Balanced performance, but not optimized for heavy disk I/O.
H-Series (High Performance Computing - HPC) 	Designed for scientific simulations, not data warehouses.
M-Series (Memory Optimized) 	Best for large in-memory databases, but not ideal for high disk I/O workloads.

Conclusion:
For a data warehouse running on an Azure Virtual Machine, the best choice is:
Storage Optimized (Ls-Series).

---


---

## Answer 2:

- Memory optimized (M-Series)

Memory optimized (M-Series)

Data warehouses typically require significant memory to handle large datasets and complex queries.  The M-series VMs are specifically designed and optimized for memory-intensive workloads, making them the best choice for running a data warehouse.

---

## Reference:

['M' family memory optimized VM size series](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/memory-optimized/m-family?tabs=mbsv3)  

The 'M' family of VM size series are one of Azure's ultra memory-optimized VM instances designed for extremely memory-intensive workloads, such as large in-memory databases, data warehousing, and high-performance computing (HPC).

---

## Q053:

You have an Azure virtual machine named VM1.

VM1 contains the following:

- a File named File1 that is stored on volume C:\
- a File named File2 that is stored on volume D:\
- an App named App1 that is in a running state
- a user named User1 that is connected to VM1

You plan to resize VM1.

What is preserved after the resize?

Select only one answer.

- File1 and File2 only
- File1 and the state of App1 only
- File1, File2 and the state of App1 only
- File1, File2, the state of App1 and the connection of User1
- File1 only

---

## Answer:
- File1 and File2 only

Resizing a VM primarily affects the compute resources (CPU, RAM).  
The data disks (and the files stored on them) are not directly affected by a resize operation.  
Therefore, File1 and File2 will be preserved.

App1: The running state of an application is not preserved across a VM resize. 
The application will likely need to be restarted.

User1: User connections are also disrupted during a resize. The user will need to reconnect.

---

## Reference:

---

## Q052:

You have a Windows Server Azure virtual machine named VM1.

You need to back up two folders in VM1 by using Azure Backup. 

The solution should minimize administrative effort.

What should you deploy first?

Select only one answer.

- Azure Backup Server
- Recovery Services agent
- Azure Connected Machine agent
- Windows Server Backup role

---

## Answer:

- Recovery Services agent


To back up files and folders directly from an Azure VM using Azure Backup, you install the Recovery Services agent (also known as the Microsoft Azure Recovery Services (MARS) agent) directly on the VM.  This agent communicates with the Recovery Services vault and handles the backup and restore operations.  No other components are required for this basic file/folder backup scenario.

> Recovery Services agent (MARS agent/Azure Backup agent): 
The Recovery Services agent (also known as the MARS agent or Azure Backup agent) is specifically designed for backing up files and folders, system state, and application data from Windows machines and Azure VMs directly to Azure Backup.  This agent is installed inside the VM and integrates with the Azure Backup service to perform backups. This seems like a very relevant option.


> Azure Backup Server (MABS): 
Azure Backup Server is an on-premises solution that can back up data to Azure. While MABS can backup files and folders, deploying and managing an entire MABS server adds significant administrative overhead. This is counter to minimizing administrative effort. MABS is generally used for more complex on-premises scenarios or when you need application-consistent backups for workloads like SQL or Exchange running in VMs.  For simply backing up folders in an Azure VM, it's overkill and increases admin effort.


> Azure Connected Machine agent: 
The Azure Connected Machine agent is used to connect on-premises (or VMs in other clouds) machines to Azure so they can be managed via Azure Arc.  While it enables management, it is not directly related to Azure Backup for files and folders within a VM. It's used for management and governance, not backup functionality itself.

> Windows Server Backup role: 
Windows Server Backup is a built-in Windows Server feature that can perform local backups or backups to network shares. While it can backup files and folders, it does not directly integrate with Azure Backup for sending backups to a Recovery Services Vault.  Using Windows Server Backup would likely involve more manual configuration, scripting to move backups to Azure Storage separately, and increased administrative effort compared to using the dedicated Azure Backup agent. It is also not the Azure-native way to leverage Azure Backup for VMs.

---

## Reference:

---

## Q051:

You have the following Azure resources:

- a virtual machine named VM1
- a Recovery Services vault named Vault1

On January 1, you configure backups for VM1 by using the following backup policy:

- Frequency: Daily
- Time: 23:00
- Timezone: (UTC) Coordinated Universal Time
- Retain instant recovery snapshot(s) for: 2 Day(s)
- Retention of daily backup point: 7 Day(s)
- Azure Backup Resource Group: Backup1RG

How many restore point collections recovery points will be stored in Backup1RG on January 10?

Select only one answer.

2
7
9
10

---

## Answer:

7

Here's why:

Daily Backups: Backups run daily at 23:00 UTC.
Retention of Daily Backup Point: Daily backups are retained for 7 days.

January 10th: On January 10th, you will have the backups from January 3rd to January 9th, inclusive. 
This makes a total of 7 days, and thus 7 restore point collections. 

The instant recovery snapshot is retained for 2 days, but this does not affect the number of
restore point collections. 
They are separate entities.

---

 ## Reference:

---

## Q050:

Your company’s Azure subscription contains an Azure virtual machine.

You need to back up the virtual machine every 12 hours.

What should you create first?

Select only one answer.

- a backup policy in a backup vault
- a standard backup policy in a recovery services vault
- an enhanced backup policy in a recovery services vault

---

## Answer:
- a standard backup policy in a recovery services vault


> Azure Backup Policies 
are central to scheduling backups. To back up something on a schedule, you must define a backup policy.

> Backup Vault vs Recovery Services Vault: 

Historically, there were Backup Vaults and Recovery Services Vaults. Now, Recovery Services Vaults 
are the primary and recommended vault for most backup scenarios, including Azure VMs. 
Backup Vaults are now more specialized and are being superseded.

> Standard vs Enhanced Backup Policies: 

Within Recovery Services Vaults, there are different types of backup policies. "Enhanced" is likely referring to the enhanced policy for Azure VMs which offers features like hourly backups and is more advanced than the older "Standard" policy. However, the term "Standard" is also generally used to refer to the common Recovery Services Vault policies.

> Standard/Recovery Services Vault Policies: 
These policies do support frequency options including "Hourly", "Daily" and "Weekly". "Hourly" frequency can be set to occur every 1, 2, 4, 6, 8, or 12 hours. Therefore, a 12-hour backup frequency is possible within a standard Recovery Services Vault policy.

> Enhanced Policies: 
"Enhanced" policies, if referring to the newer enhanced policy types, are usually focused on granular restores and potentially different storage efficiencies. For a simple 12-hour frequency, an "enhanced" policy might not be strictly necessary.

---

## Reference:

---

## Q049:

You have an Azure virtual machine named Computer5 and a Recovery Services vault named Vault5. 

Computer5 contains the following data disks:

- DiskA has a size of 512 GB
- DiskB has a size of 30 TB
- DiskC has a size of 26 TB
- DiskD has a size of 2.0 TB

Which data disks can you back up to Vault5?

Select only one answer.

- DiskA, DiskB, DiskC, and DiskD
- DiskA only
- DiskB only
- DiskC only
- DiskD only

---

## Answer:

- DiskA, DiskB, DiskC, and DiskD

Azure Backup has limits on the size of disks it can back up. 
Currently, the limit for a single disk is 32 TB.  

All disks are within the size limit of 32 TB. 
Therefore, all of them can be backed up.

---

## Reference:


---

## Q048:

You have an Azure subscription that contains a storage account named storage1 
and the following virtual machines:

- VM1 has a public IP address of 13.68.158.24 and is connected to VNET1/Subnet1
- VM2 has a public IP address of 52.255.145.76 and is connected to VNET1/Subnet1
- VM3 has a public IP address of 13.68.158.50 and is connected to VNET1/Subnet2

The subnets have the following service endpoints:

- Subnet1 has a Microsoft.Storage service endpoint
- Subnet2 does NOT have any service endpoint

Storage1 has a firewall configured to allow access from the 13.68.158.0/24 IP address range only.

Which virtual machines can access storage1.

Select only one answer.

- VM1 and VM2 only
- VM1 and VM3 only
- VM1 only
- VM1, VM2, and VM3
- VM3 only

---

## Answer 3:
- VM1, VM2, and VM3

The problem here is to figure out whether 

VM2 has a public IP address of 52.255.145.76 and is connected to VNET1/Subnet1

can access storage1 or not.

[Secure Azure services to virtual networks](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview#secure-azure-services-to-virtual-networks)  

With service endpoints, the source IP addresses of the virtual machines in the subnet for service traffic switches from using public IPv4 addresses to using private IPv4 addresses. Existing Azure service firewall rules using Azure public IP addresses will stop working with this switch. Please ensure Azure service firewall rules allow for this switch before setting up service endpoints. You may also experience temporary interruption to service traffic from this subnet while configuring service endpoints.

Today, Azure service traffic from a virtual network uses public IP addresses as source IP addresses. With service endpoints, service traffic switches to use virtual network private addresses as the source IP addresses when accessing the Azure service from a virtual network. This switch allows you to access the services without the need for reserved, public IP addresses used in IP firewalls.

This means that VM2 in Subnet1 will reach storage1 with its private address and not its 
public address and therefore the Firewall rule on storage1 si bypassed.

---

## Answer 2:

Correct Answer:
VM1 and VM3 only

Explanation:
Azure Storage Firewalls and Virtual Networks control access to storage accounts based on:

IP Address Rules (Allowing specific public IP ranges)
Virtual Network Service Endpoints (Allowing private network access via subnets)

Storage1 Access Rules:
Firewall allows access from 13.68.158.0/24 (which includes VM1 and VM3 but not VM2).
Subnet1 has a Microsoft.Storage service endpoint, allowing private access to Storage1 for VMs in Subnet1.
Subnet2 does NOT have a service endpoint, so only public IP filtering applies.

Virtual Machines & Their Access:
VM	Public IP Address	Subnet	Service Endpoint	Matches Firewall Rule (13.68.158.0/24)?	Can Access Storage1?
VM1	13.68.158.24	    Subnet1	 Yes	            Yes (Allowed via IP range)	            Yes
VM2	52.255.145.76	    Subnet1	 Yes	            No (Not in 13.68.158.0/24)	            No
VM3	13.68.158.50	    Subnet2	 No	                Yes (Allowed via IP range)	            Yes    

---

## Answer 1:
- VM1, VM2, and VM3

Here's the breakdown:

> VM1:  

From the Service Endpoint perspective:
VM1 is in Subnet1 which has a has a Microsoft.Storage service endpoint
Therefore, VM1 can access storage1.

From the Firewall rule perspective: 
VM1's public IP (13.68.158.24) falls within the allowed IP range (13.68.158.0/24).  
Therefore, VM1 can access storage1.

> Conclusion : VM1 can access storage1.

> VM2:

From the Service Endpoint perspective:
VM2 is in Subnet1 which has a has a Microsoft.Storage service endpoint
Therefore, VM2 can access storage1.

From the Firewall rule perspective: 
VM2: VM2's public IP (52.255.145.76) is outside the allowed IP range.  
Therefore, VM2 cannot access storage1 according to the Firewall rule on the storage account.

> Conclusion : VM2 can access storage1.

Turning on firewall rules for your storage account blocks incoming requests for data by default, 
unless the requests originate from a service that operates within an Azure virtual network or from 
allowed public IP addresses. 

Requests that are blocked include those from other Azure services, from the Azure portal, and from logging 
and metrics services.

Therefore, VM2 can access storage1 because it reaches it via its private address due to the Service Endpoint
that is set on its Subnet1.

> VM3:  

From the Service Endpoint perspective:
VM3 has a public IP address of 13.68.158.50 and is connected to VNET1/Subnet2 and Subnet2 does not have a SE
to the Storage Account therefore it will reach it over its public IP address because using service endpoints 
does not remove the public endpoint from Azure SQL or Azure Storage accounts, it's just a redirection of traffic
through the wouting table of teh subnet.

From the Firewall rule perspective: 
VM3: VM3's public IP (13.68.158.50) falls within the allowed IP range. 
Therefore, VM3 can access storage1. 

> Conclusion : VM3 can access storage1.

---

## Reference:

[Configure Azure Storage firewalls and virtual networks](https://learn.microsoft.com/en-us/azure/storage/common/storage-network-security?tabs=azure-portal)  

Turning on firewall rules for your storage account blocks incoming requests for data by default, 
unless the requests originate from a service that operates within an Azure virtual network or from 
allowed public IP addresses. 

Requests that are blocked include those from other Azure services, from the Azure portal, and from logging 
and metrics services.

---

## Q047:

You have an Azure network security group (NSG) named NSG1 that 
is associated to a virtual network subnet named Subnet1. 

NSG1 has the following inbound security rules:

- Rule1 has a priority of 100 and allows port 3389 on TCP protocol from any source and to any destination
- Rule2 has a priority of 200 and allows ports 80 and 8080 on UDP protocol from any source and to any destination
- Rule3 has a priority of 300 and denies ports 1-2000 on TCP protocol from any source and to any destination
- Rule4 has a priority of 400 and allows ports 50-500 on TCP protocol from VirtualNetwork source and to any destination
- Rule5 has a priority of 500 and allows ports 80 and 443 on TCP protocol from any source and to any destination

You need to allow http and https connections from the internet to Subnet1.

What should you change for NSG1?

Select only one answer.

- Priority for Rule3 to 450
- Priority for Rule4 to 250
- Priority for Rule5 to 250
- Protocol for Rule2 to TCP

---

## Answer:
- Priority for Rule4 to 250

Here's why:

HTTP/HTTPS: These protocols use TCP ports 80 and 443, respectively.

> Rule5: 
This rule already allows ports 80 and 443 on TCP.

> Priority: 
NSG rules are processed in order of priority, lowest number first. Currently, Rule3 (priority 300) denies ports 1-2000 on TCP. Since Rule5 (priority 500) comes after Rule3, the deny rule takes precedence. By changing the priority of Rule5 to 250, it will be processed before Rule3, effectively allowing HTTP/HTTPS traffic.

---

## Reference:

---

## Q046:

You have an Azure subscription that includes following resources:

- VNet1, a virtual network
- Subnet1, a subnet in VNet1
- VM1, a virtual machine
- NIC1, a network interface of VM1
- LB1, a load balancer

You create a network security group named NSG1.

To which two Azure resources can you associate NSG1?

Select all answers that apply.

- LB1
- NIC1
- Subnet1
- VM1
- VNet1

---

## Answer:

- NIC1
- Subnet1

> NIC1: 
You can associate an NSG directly with a network interface card (NIC). 
This applies the network security rules to the specific VM connected to that NIC.

> Subnet1: 
You can also associate an NSG with a subnet. This applies the network security rules to all resources within that subnet, including VMs. This is a common and efficient way to manage network security for a group of resources.

> LB1 (Load Balancer): 

Load balancers themselves don't directly have NSGs associated. 
NSGs are associated to the backend pool resources (VMs or NICs) and sometimes subnet where backend pool resources reside.

---

## Reference:

---

## Q045:

You have an Azure subscription that contains a virtual machine named VM1 and a storage account named storage1.
You need to ensure that VM1 can access storage1 by using a private IP address.

What should you use?

Select only one answer.

- a point to site (P2S) connection
- a service endpoint
- a VPN gateway
- the Azure Front Door service

---

## Answer:

- a service endpoint.

Service endpoints for Azure Storage allow you to connect from your virtual network (and thus VMs within it) to Azure Storage over a private IP address, without traversing the public internet.  This keeps the traffic within the Azure network, enhancing security.

---

## Reference:

---

## Q044:

You have an Azure Storage account named storage1.

You create the following encryption scopes for storage1:

- Scope1 that has an encryption type of Microsoft-managed keys
- Scope2 that has an encryption type of Customer-managed keys

Which storage services can be used with Scope2?

Select only one answer.

- blob and file only
- blob, file, table, and queue
- blob only
- file only
- table and queue only

---

## Answer:

- blob only

Customer-managed keys (CMK) for encryption at rest are currently only supported for Azure Blob storage.  
While Microsoft-managed keys can be used with other storage services (file, table, queue), 
CMK is specifically a blob storage feature.

---

## Reference:

---

## Q043:

You have an Azure storage account named storage1.

You need to ensure that a user named User1 can access storage1 only from January 1st to January 31st 2024.

What should you do?

Select only one answer.

- Create a conditional access policy for User1
- Provide User1 with a shared access signature (SAS)
- Provide User1 with a storage1 access key
- Use a condition when assigning User1 an RBAC role on storage1

---

## Answer:

Provide User1 with a shared access signature (SAS).

SAS tokens allow you to grant granular, time-limited access to specific Azure Storage resources.  You can create a SAS token that grants User1 access to storage1 (or specific containers/blobs within it) and set the start and expiry times to January 1st and January 31st, 2024, respectively.  This is the most precise and appropriate method for controlling access within a specific timeframe.

---

## Reference:

---

## Q042:

You have an Azure subscription.

You plan to create a storage account that contains the following settings:

- Name: storage1
- Performance: Standard
- Redundancy: Zone-redundant storage (ZRS)

What is the minimum number of copies of storage1 data stored in Azure?

Select only one answer.

2
3
6
9

---

## Answer:

- 6

Zone-redundant storage (ZRS) synchronously replicates your data across three Azure availability zones in the primary region.  Each zone itself has multiple copies of your data.  While the exact number within a zone isn't publicly disclosed, it's safe to say it's more than one.  Therefore, with ZRS, you have data copies in at least three zones, with multiple copies within each zone, making the total number of copies at least six.

---

## Reference:

---

## Q041:

You have an Azure Storage account named storage1 that is configured to use the Hot access tier.
Storage1 has a container named container1 and the lifecycle management rule with following settings:

Move blob to cool storage: Selected
Days after last modification: 3

Move blob to archive storage: Selected
Days after last modification: 5

On December 1, you create a file named File1 in container1.
On December 10, you rehydrate File1 and move the file to the Hot access tier.

When will File1 be moved to archive storage?

Select only one answer.

- on December 15
- on December 18
- on January 1
- within 24 hours

---

## Answer 2:

Correct Answer:
On December 15

Explanation:
Azure Lifecycle Management moves blobs between tiers based on the last modification date.

Timeline of File1:
December 1 → File1 is created in Hot tier.
December 4 → Moved to Cool tier (since 3 days have passed).
December 6 → Moved to Archive tier (since 5 days have passed).
December 10 → File1 is rehydrated and moved back to Hot tier.
December 10 is now the new last modification date.
December 13 → File1 will move to Cool tier (3 days after modification).
December 15 → File1 will move to Archive tier (5 days after modification).
Thus, File1 will be moved to Archive storage on December 15.

---

## Answer 1:

On December 15th.

Here's why:

Initial Creation: File1 is created on December 1st.

> Rehydration: 

On December 10th, File1 is moved back to the Hot tier. 
This resets the lifecycle management timer. 
The "days after last modification" count starts again from the rehydration date.

> Archive Move: 
The rule states "move to archive storage after 5 days." 
Five days after December 10th is December 15th.

---

## Reference:

---

## Q040:

You plan to create an Azure container instance named container1 that will use a Docker image named Image1.
You need to ensure that container1 has persistent storage.
Which Azure resources should you deploy for the persistent storage?

Select only one answer.

- an Azure container registry
- an Azure SQL database
- an Azure Storage account and a blob container
- an Azure Storage account and a file share

---

## Answer:

- An Azure Storage account and a file share.

Azure Container Instances can use Azure File shares for persistent storage.  You create a Storage Account, then within it, you create a File Share.  This file share is then mounted into the container instance, providing a location that persists data even if the container restarts or is replaced.

---

## Reference:

---

## Q039:

You have Azure subscription that includes virtual network named VNet1 in West US region.

You plan to deploy following container instances:

- instance1, running Windows container image in West US region
- instance2, running Linux container image in West US region
- instance3, running Windows container image in East US region

Which container instances can be deployed to VNet1?

Select only one answer.

- instance1 and instance2 only
- instance1 and instance3 only
- instance1, instance2 and instance3
- instance1 only
- instance2 only

---

## Answer:

- instance1 and instance2 only

Container instances must be in the same region as the virtual network they are being deployed into.  
Since VNet1 is in West US, only instance1 (Windows, West US) and instance2 (Linux, West US) can be deployed to it. 
Instance3 is in East US, so it cannot be deployed to VNet1.

---

## Reference:

---

## Q038:

You have an Azure container registry that stores an image named Image1 
and a Windows Server 2022 Azure virtual machine named VM1.

You need to ensure that you can run Image1 in VM1.

What should you install in VM1?

Select only one answer.

- Azure Portal
- Docker
- Hyper-V role
- .NET Framework 4.8

---


## Answer-2:

To run Image1 (a container image) on VM1 (a Windows Server 2022 VM), you need a container runtime.

Analysis of the given options:

Azure Portal The portal is a management interface and does not provide container execution capabilities.
Docker is required to run container images from Azure Container Registry (ACR).
Hyper-V role is for virtual machines, not container execution.
.NET Framework 4.8 is necessary for .NET apps, not required for running containers.

Correct Answer: Docker

Reason: Docker is needed to pull and run container images from Azure Container Registry on a Windows Server 2022 VM.

---

## Answer-1:
- Docker

> Hyper-V role: 
Hyper-V is a hypervisor-based virtualization technology by Microsoft. While Docker can use Hyper-V as a backend on Windows, installing just the Hyper-V role alone is not sufficient to run Docker containers. Docker itself needs to be installed to manage and run containers. While enabling Hyper-V might be a prerequisite for certain Docker setups on Windows, it is not the direct answer for "What should you install in VM1 to run Image1".  Docker is the tool that directly runs and manages containers.

---

## Reference:

---

## Q037:

You have an Azure app service web app named WebApp1 that runs in the Standard App Service plan.
You plan to add deployment slots for WebApp1.
What is the maximum number of deployment slots that you can add to WebApp1?

Select only one answer.

1
4
6
9

---

## Answer 2:
- 4

The maximum number of deployment slots available depends on the App Service Plan tier.

Key Information:

Free (F1) & Shared (D1): No deployment slots
Basic (B1, B2, B3):  No deployment slots
Standard (S1, S2, S3): 5 total slots (including the production slot) → 4 additional slots
PremiumV2 (P1V2, P2V2, P3V2):  6 total slots
PremiumV3 (P1V3 and above): 20 total slots
Isolated (I1 and above): 20 total slots

Answer:
4 (Since Standard App Service Plan allows a maximum of 5 slots, including production, you can add 4 additional deployment slots.)

[Set up staging environments in Azure App Service](https://learn.microsoft.com/en-us/azure/app-service/deploy-staging-slots?tabs=portal)  

Each App Service plan tier supports a different number of deployment slots. 
There's no extra charge for using deployment slots.
To find out the number of slots your app's tier supports, see: 

[App Service limits](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits#azure-app-service-limits)  

Staging slots per app:				
- Standard 5	
- Premium v1-v3:
- Isolated20	20

---

## Answer 1:

- 6

Standard tier App Service Plans allow for a maximum of 6 deployment slots.

Free and Shared plans: Do not support deployment slots.
Basic plan: Does not support deployment slots.
Standard plan: Supports deployment slots, but with a limit.
Premium and Isolated plans: Support deployment slots with a higher limit.

The standard limit for Standard tier is 6 slots plus the production slot, making it a total of 7.  

---

## Reference:

---

## Q036:

You have the following web apps:

- WebApp1, that runs on Windows Server 2016
- WebApp2, that runs on Windows Server 2022
- WebApp3, that runs on Ubuntu Server
- WebApp4, that runs on Red Hat Enterprise Linux

You plan to migrate the web apps to Azure app services web apps.
You need to create the app service plans for the web apps.
What is the minimum number of app service plans that should be created?

Select only one answer.

1
2
3
4

---

## Answer:
- 2

The user is asking about the minimum number of App Service Plans required 
to host four web apps with different operating systems when migrating 
them to Azure App Services.

> What is an App Service Plan? 

It defines the set of compute resources (VMs) dedicated to running your app(s). 
Apps within the same App Service plan share the same compute resources

> Operating system constraints in App Service Plans: App Service Plans are OS-specific.  
Are there restrictions on which operating systems can be hosted on the same App Service Plan?

Based on the OS compatibility restriction, we need to group the web apps based on their OS 
requirement and allocate App Service Plans accordingly.

---

## Reference:

---

## Q035:

You have an Azure subscription that includes a virtual network named VNet1.
You plan to create a web app named WebApp1 and deploy it to VNet1.
You need to prepare the environment for the planned web app. 
The solution must minimize costs.

Which app service plan size should you use?

Select only one answer.

- Dev / Test B1
- Dev / Test F1
- Isolated I1V2
- Production P1V2
- Production P3V3

---

## Answer:
- Production P1V2

> Comparing cost: 

Isolated > Premium P3V3 > Premium P1V2 > Basic B1 > Free F1.

From the options that support VNet integration: 
Isolated I1V2, Production P1V2, Production P3V3, the least expensive is Production P1V2.


> Production P1V2 (Premium Tier): 

Premium tier App Service Plans do support VNet Integration.  Specifically, they support Regional VNet Integration, which allows your web app to access resources within your VNet. Premium tier plans are designed for production workloads and are more expensive than Basic or Free, but significantly less expensive than Isolated.

> Production P3V3 (Premium Tier): 

Premium tier App Service Plans (including P3V3) also support VNet Integration. P3V3 is a larger and more powerful instance size within the Premium tier, and therefore more expensive than P1V2. While it supports VNet integration, it is not the most cost-effective Premium option if P1V2 is sufficient for the workload.


> Isolated I1V2

To deploy a web app to a virtual network, you must use an App Service Plan in the Isolated tier.  The other tiers (Dev/Test and Production) do not support VNet integration.  Since minimizing cost is a requirement, I1V2 is the smallest Isolated tier plan.

Let's analyze each option and its VNet integration capabilities and cost:

> Dev / Test B1 (Basic Tier): 

Basic tier does not support VNet integration. It's cheaper, but doesn't meet the requirement.

> Dev / Test F1 (Free Tier): 

Free tier also does not support VNet integration. It's the cheapest but doesn't meet the requirement.

> Isolated I1V2 (Isolated Tier): 

Isolated tier does support VNet integration, and in fact, it's the only tier that allows a Web App to be fully deployed inside a VNet (App Service Environment). Isolated tier is generally the most expensive option as it provides dedicated resources.

> Production P1V2 (Premium Tier): 

Premium tier does support VNet integration, specifically Regional VNet Integration. This allows the Web App to access resources within the VNet. Premium tiers are production-level and more expensive than Basic/Free but generally less expensive than Isolated.

> Production P3V3 (Premium Tier): 

Similar to P1V2, P3V3 (Premium V3 tier) also supports Regional VNet Integration. P3V3 is more powerful (and more expensive) than P1V2 but still in the Premium category and supports VNet integration.

---

## Reference:


---

## Q034:

You plan to deploy an Azure web app that will have the following settings:

Name: WebApp1
Publish: Docker Container
Operating system: Windows
Region: West US
Windows Plan (West US): ASP-RG1-8bcf

You need to ensure that WebApp1 uses the ASP.NET V4.8 runtime stack.

Which setting should you modify?

- Operating system
- Publish
- Region
- Windows Plan

---

## Answer2:
- Publish

To ensure that WebApp1 uses the ASP.NET V4.8 runtime stack, you need to modify 
the Publish setting.

> Explanation-1:

ASP.NET V4.8 is only supported on Windows App Services when using the "Code" publishing 
option, not Docker Containers.

Since your current configuration specifies "Publish: Docker Container", it means you're deploying a containerized 
application, which doesn't use the built-in ASP.NET V4.8 runtime from Azure. To use the ASP.NET V4.8 runtime stack, 
you must change the Publish setting from "Docker Container" to "Code".

> Explanation-2:

[You need to ensure that WebApp1 uses the ASP.NET v4.7 runtime stack [closed]](https://stackoverflow.com/questions/70440097/you-need-to-ensure-that-webapp1-uses-the-asp-net-v4-7-runtime-stack)

You have to modify the publish  setting from DockerContainer to code.

While deploying the web app: 

1. if you choose the code in publish setting: 
then you will be able select the specific  runtime language on which you want your webapp to run as show below.

2. if you choose the DockerContainer in publish setting: 
then you won't be able to select the runtime on which your web app has to run as shown in below.


## Reference:

[You need to ensure that WebApp1 uses the ASP.NET v4.7 runtime stack [closed]](https://stackoverflow.com/questions/70440097/you-need-to-ensure-that-webapp1-uses-the-asp-net-v4-7-runtime-stack)  
[What is the "Code" radio button for Publishing in Azure App Services for when Creating a Web App?](https://stackoverflow.com/questions/74303799/what-is-the-code-radio-button-for-publishing-in-azure-app-services-for-when-cr)  
[Is it possible to convert the publish method of an App Service from Code to Docker?](https://stackoverflow.com/questions/62924348/is-it-possible-to-convert-the-publish-method-of-an-app-service-from-code-to-dock/74155094)  
[az webapp create](https://learn.microsoft.com/en-us/cli/azure/webapp?view=azure-cli-latest#az-webapp-create)  
[Migrate custom software to Azure App Service using a custom container](https://learn.microsoft.com/en-us/azure/app-service/tutorial-custom-container?pivots=container-linux&tabs=azure-cli)  

> publish code option: 

with the publish code option it is possible to set the runtimes yo run the code on.
This results in Azure Web App fetching the code, and running it on the specified runtime. 
In the backgroud what realy happens is that Azure Wen apps will use a well known base container 
with the specified runtime in it and bring in your code.

In the end, you shouldn't have a problem deploying a container based web app on the same App Service Plan even though the original deployment was using Code Base.

you should rely on the Azure CLI more since the portal sometimes doesn't provide you with the full power.

Also hav a look at the App Service Swapping method, to move your traffic from your code base to your container base.

[Why is "Azure App Service Container" publish option missing in Visual Studio 2022](https://learn.microsoft.com/en-us/answers/questions/1181103/why-is-azure-app-service-container-publish-option)    
[App Service: Run a custom container in Azure](https://learn.microsoft.com/en-us/azure/app-service/quickstart-custom-container?tabs=dotnet&pivots=container-windows-vs)   
[Configure a custom container for Azure App Service](https://learn.microsoft.com/en-us/azure/app-service/configure-custom-container?tabs=debian&pivots=container-linux)  


---

## Answer1:

- Windows Plan

The user wants to deploy an Azure Web App with specific settings.
The requirement is that the WebApp needs to use ASP.NET V4.8 runtime.
The question is which setting needs to be modified to ensure this runtime.

Let's analyze each setting option and its relevance to ASP.NET runtime.

> Operating System:  

The user has selected Windows as the OS. ASP.NET is primarily associated with Windows. While ASP.NET Core can run cross-platform, ASP.NET Framework (like v4.8) is tied to Windows.  Changing OS to Linux would definitely not support ASP.NET v4.8. So, OS itself doesn't seem to be the setting to modify to get v4.8 but rather to ensure it's possible to use v4.8.

> Publish: 

Docker Container: Publishing as a Docker container means the application and its runtime environment are packaged within a container. This could be relevant. If the base Docker image for Windows is not configured with ASP.NET v4.8, then it won't be available. However, within a Docker container, you have control over what's installed. It's possible to build a Docker image with Windows and ASP.NET v4.8.  So 'Publish' itself isn't the setting that directly dictates the runtime stack, but it influences how the runtime environment is set up.

> Region: 

Region (West US) is a geographical location for the Azure service.  Region typically affects latency, data residency, and availability zones. It is unlikely that the Region setting directly controls the ASP.NET runtime version. Azure services are generally consistent in terms of available runtimes across regions.

> Windows Plan:  

`Windows Plan (ASP-RG1-8bcf)` refers to the App Service Plan, which defines the underlying compute resources, features, and capabilities available to the web app. 

This is the most likely candidate.  

The App Service Plan tier can influence the available features and default configurations. Different plans might offer different default runtime stacks or have restrictions. It is possible that the selected Windows Plan (ASP-RG1-8bcf) doesn't have ASP.NET V4.8 configured by default, or maybe it defaults to a different version.  Changing the Windows Plan might offer options to select or ensure the desired ASP.NET runtime.

To confirm, let's think about how Azure Web Apps handle ASP.NET runtime versions:

Typically, you select the .NET Framework version when creating or configuring the Web App. 

This is usually linked to the App Service Plan or the configuration settings of the Web App itself.
App Service Plans define the features available. It's reasonable to assume that different plans might offer different sets of pre-installed runtimes or allow more customization.

To be even more certain, let's quickly search Azure documentation related to Web App ASP.NET runtime version selection and App Service Plans.

A quick search confirms that App Service Plan tier can influence the available features and settings. When configuring an Azure Web App, you usually configure the .NET Framework version under Application settings or Configuration blade in the Azure portal.  This could be linked to the underlying plan.  While not explicitly stated that the "Windows Plan" directly sets the runtime version, it's the most likely factor that restricts or enables certain runtimes.

---

## Reference:

[You need to ensure that WebApp1 uses the ASP.NET v4.7 runtime stack [closed]](https://stackoverflow.com/questions/70440097/you-need-to-ensure-that-webapp1-uses-the-asp-net-v4-7-runtime-stack)

---

# Failed Assessment date: January 5, 2025: Modules to study

---





Because you scored lower in "Manage users and groups in Microsoft Entra ID":
Manage users and groups in Microsoft Entra ID
50 mins

---

## Q03X:

---

## Answer:

---

## Reference:

---

Because you scored lower in "Host a web application with Azure App Service":
[Host a web application with Azure App Service](https://learn.microsoft.com/en-us/training/modules/host-a-web-app-with-azure-app-service/)  
[Hosten einer Webanwendung mit Azure App Service](https://learn.microsoft.com/de-de/training/modules/host-a-web-app-with-azure-app-service/)  
31 mins


---

Because you scored lower in "Secure and isolate access to Azure resources by using network security groups and service endpoints":
[Secure and isolate access to Azure resources by using network security groups and service endpoints](https://learn.microsoft.com/en-us/training/modules/secure-and-isolate-with-nsg-and-service-endpoints/)    
[Sichern und Isolieren des Zugriffs auf Azure-Ressourcen mithilfe von Netzwerksicherheitsgruppen und Dienstendpunkten](https://learn.microsoft.com/de-de/training/modules/secure-and-isolate-with-nsg-and-service-endpoints/)  
43 mins

---


Because you scored lower in "Build a containerized web application with Docker":
[Build a containerized web application with Docker](https://learn.microsoft.com/en-us/training/modules/intro-to-containers/)   
[Erstellen einer containerisierten Webanwendung mit Docker](https://learn.microsoft.com/de-de/training/modules/intro-to-containers/)  
57 mins


---

Because you scored lower in "Secure your Azure Storage account":
[Secure your Azure Storage account](https://learn.microsoft.com/en-us/training/modules/secure-azure-storage-account/)  
[Sichern Ihres Azure-Speicherkontos](https://learn.microsoft.com/de-de/training/modules/secure-azure-storage-account/)  
45 mins

---

## Q034:

Welche Azure-Dienste erkennen Anomalien bei Kontoaktivitäten, und senden Ihnen Benachrichtigungen 
über potenziell schädliche Zugriffsversuche auf Ihr Konto? 

- Azure Defender für Storage
- Sicherheitsfunktionen des Azure-Speicherkontos
- Verschlüsselung während der Übertragung

---

## Answer:
- Azure Defender für Storage

Microsoft Defender für Speicher erkennt Anomalien bei der Kontoaktivität. 
Sie werden benachrichtigt, wenn erkannt wird, dass sich jemand unrechtmäßig 
Zugriff zu Ihrem Konto verschaffen möchte.

---

## Reference:

---

## Q033:

Was ist die Standardnetzwerkregel, wenn Sie den Netzwerkzugriff auf Ihr Azure-Speicherkonto konfigurieren? 

- Alle Verbindungen aus allen Netzwerken zulassen
- Alle Verbindungen von einem privaten IP-Adressbereich zulassen
- Alle Verbindungen aus allen Netzwerken ablehnen

---

## Answer:
- Alle Verbindungen aus allen Netzwerken zulassen

Richtig. Die Standardnetzwerkregel besteht darin, alle Verbindungen von allen Netzwerken zuzulassen.

---

## Reference:

---

## Q032:

Sie arbeiten an einem Projekt mit einem Drittanbieter, um eine Website für einen Kunden zu erstellen. 
Die Imageobjekte, die auf der Website verwendet werden, werden in Ihrem Azure Speicherkonto gespeichert, 
das Teil Ihres Abonnements ist. Sie möchten für einen begrenzten Zeitraum Lesezugriff auf diese Daten erhalten. 
Welche Sicherheitsoption verwenden Sie dazu am besten? 

- CORS-Support
- Speicherkonto
- Shared Access Signatures


---

## Answer:
- Shared Access Signatures

Richtig. 

Eine SAS ist eine Zeichenfolge, die ein Sicherheitstoken enthält, das an einen URI angefügt werden kann. 
Verwenden Sie eine SAS, um den Zugriff auf ein Speicherobjekt zu delegieren und Einschränkungen festzulegen, 
z.B. Berechtigungen und den Zeitraum des Zugriffs.

---

## Reference:

---

Because you scored lower in "Configure virtual machine availability":
[Configure virtual machine availability](https://learn.microsoft.com/en-us/training/modules/configure-virtual-machine-availability/)  
[Konfigurieren der Verfügbarkeit virtueller Computer](https://learn.microsoft.com/de-de/training/modules/configure-virtual-machine-availability/)  
64 mins
> Module:
[AZ-104: Deploy and manage Azure compute resources](https://learn.microsoft.com/en-us/training/paths/az-104-manage-compute-resources/)  
[AZ-104: Bereitstellen und Verwalten von Azure-Computeressourcen](https://learn.microsoft.com/de-de/training/paths/az-104-manage-compute-resources/)

> Knowledge check:

Your organization has diverse requirements for the configuration and availability of their virtual machines. 
You're responsible for helping with the configuration to fulfill requests and resolve issues.

The Admin team is testing an implementation of Azure Virtual Machine Scale Sets with five virtual machines. 
During testing, monitoring alerts show all virtual machines running at maximum capacity. 
However, you discover that when the CPU is fully consumed more virtual machines aren't deploying in the scale set.

The DevOps team wants to configure Azure Virtual Machine Scale Sets for their production servers. 
Thursday evening is typically the busiest time in preparation for delivery to customers by COB on Friday. Conversely, early Monday is generally the quietest time. You need a plan to add more machines when the workload is high.

As load increases on applications hosted in Azure Virtual Machine Scale Sets, 
you want to increase the CPU capacity of the existing instances rather than deploy more instances.

> Wissensbeurteilung:

Ihre Organisation stellt an die Konfiguration und Verfügbarkeit ihrer virtuellen Computer (VMs) verschiedene Anforderungen. Sie sind mitverantwortlich für die Konfiguration, um Anforderungen zu erfüllen und Probleme zu lösen.

Das Admin-Team testet eine Azure Virtual Machine Scale Sets-Implementierung mit fünf VMs. Während der Tests zeigen die Überwachungswarnungen, dass alle VMs mit maximaler Kapazität ausgeführt werden. Sie stellen jedoch fest, dass bei vollständiger Auslastung der CPU keine weiteren VMs in der Skalierungsgruppe bereitgestellt werden.

Das DevOps-Team möchte Azure Virtual Machine Scale Sets für seine Produktionsserver konfigurieren. Der Donnerstagabend ist in der Regel die arbeitsreichste Zeit, da die Auslieferung an die Kunden bis zum Geschäftsschluss am Freitag vorbereitet wird. Umgekehrt ist der Montagvormittag im Allgemeinen die ruhigste Zeit. Sie benötigen einen Plan, um weitere Computer hinzuzufügen, wenn die Arbeitsauslastung hoch ist.

Bei steigender Auslastung von Anwendungen, die in Azure Virtual Machine Scale Sets gehostet werden, sollten Sie die CPU-Kapazität der vorhandenen Instanzen erhöhen, anstatt weitere Instanzen bereitzustellen.

---

## Q031:

Welche Arten der Skalierung können Sie verwenden, um die CPU-Kapazität für Ihre vorhandenen Virtual Machine Scale Sets-Instanzen zu erhöhen? 

- Horizontale Skalierung
- Vertikale Skalierung
- Lastenausgleich

What types of scaling can you use to increase the CPU capacity for your existing Virtual Machine Scale Sets instances? 

- Horizontal scaling
- Vertical scaling
- Load balancing

---

## Answer:
- Vertikale Skalierung
- Vertical scaling

Durch eine vertikale Skalierung wird die Kapazität der vorhandenen Instanzen innerhalb von 
Azure Virtual Machine Scale Sets erhöht.

Vertical scaling increases the capacity of existing instances within Azure Virtual Machine Scale Sets.

---

## Reference:

---

## Q030:

Welches Feature für Virtual Machine Scale Sets fügt weitere virtuelle Computer hinzu und vermeidet die intensiven Vorbereitungszeiten? 

- Zeitplanbasierte Regeln
- Autoscale
- Metrikbasierte Regeln

Which Virtual Machine Scale Sets feature adds more virtual machines and avoids the busy preparation times? 

- Schedule-based rules
- Autoscale
- Metric-based rules

---

## Answer:
- Zeitplanbasierte Regeln
- Schedule-based rules

Mit zeitplanbasierten Regeln planen Administratoren die Skalierungsgruppe proaktiv, 
um eine oder eine beliebige Anzahl Instanzen bereitzustellen.

With schedule-based rules, administrators proactively schedule the scale set to deploy one or any number of instances.

---

## Reference:


---

## Q029:

Wie können Sie sicherstellen, dass weitere VMs für das Admin-Team bereitgestellt werden, 
wenn die CPU zu 75 % ausgelastet ist? 

- Sie erhöhen die Anzahl der Instanzen manuell.
- Sie ändern den CPU-Prozentsatz in 50 %.
- Sie aktivieren die Option für die automatische Skalierung.

How can you ensure more virtual machines are deployed for the Admin team when the CPU is 75% consumed? 

- Manually increase the instance count.
- Change the CPU percentage to 50%.
- Enable the autoscale option.

---

## Answer:
- Sie aktivieren die Option für die automatische Skalierung.
- Enable the autoscale option.

Um die Anforderungen des Szenarios für das Admin-Team zu erfüllen, 
aktivieren Sie die Option zur automatischen Skalierung, damit weitere VMs 
erstellt werden, wenn die CPU zu 75 % ausgelastet ist.

To meet the Admin team scenario requirements, enable the autoscale option 
so more virtual machines are created when the CPU is 75% consumed.

---

## Reference:

---

Because you scored lower in "Protect your virtual machines by using Azure Backup":
[Protect your virtual machines by using Azure Backup](https://learn.microsoft.com/en-us/training/modules/protect-virtual-machines-with-azure-backup/)   
[Schützen Ihrer virtuellen Computer mithilfe von Azure Backup](https://learn.microsoft.com/de-de/training/modules/protect-virtual-machines-with-azure-backup/)  
35 mins
> Module:
[AZ-104: Monitor and back up Azure resources](https://learn.microsoft.com/en-us/training/paths/az-104-monitor-backup-resources/)  
[AZ-104: Überwachen und Sichern von Azure-Ressourcen](https://learn.microsoft.com/de-de/training/paths/az-104-monitor-backup-resources/)

---

## Q028:


Sie möchten den Datenträger einer vorhandenen VM ersetzen, erhalten aber einen Fehler. 
Was könnte der Grund dafür sein? 

- Die vorhandene VM wurde gelöscht und ist nicht mehr verfügbar.
- Die vorhandene VM gehört zu einer anderen Ressourcengruppe in Ihrem Azure-Abonnement.
- Die vorhandene VM ist deaktiviert.

You want to replace a disk on an existing VM but receive an error. 
What's the possible reason? 

- The existing VM is deleted and is no longer available.
- The existing VM is part of a different resource group in your Azure subscription.
- The existing VM is turned off

---

## Answer:
- Die vorhandene VM wurde gelöscht und ist nicht mehr verfügbar.
- The existing VM is deleted and is no longer available.

Wenn die VM gelöscht wurde, kann der Datenträger nicht wiederhergestellt werden.
If the VM was deleted, the disk can't be restored.

---

## Reference:

> [Vorhandene ersetzen](https://learn.microsoft.com/de-de/training/modules/protect-virtual-machines-with-azure-backup/5-restore-virtual-machine-data):	

Sie können einen Datenträger wiederherstellen und dazu verwenden, einen Datenträger auf der vorhandenen VM zu ersetzen. Azure Backup erstellt eine Momentaufnahme der vorhandenen VM, bevor der Datenträger ersetzt wird. Die Momentaufnahme wird an einem von Ihnen angegebenen Stagingspeicherort gespeichert. Vorhandene Datenträger, die mit der VM verknüpft sind, werden durch den ausgewählten Wiederherstellungspunkt ersetzt. Der aktuelle virtuelle Computer muss jedoch vorhanden sein. 
**Sie können diese Option nicht verwenden, wenn der virtuelle Computer gelöscht wird**.

> [Replace existing](https://learn.microsoft.com/en-us/training/modules/protect-virtual-machines-with-azure-backup/5-restore-virtual-machine-data):

You can restore a disk and use it to replace a disk on the existing VM. Azure Backup takes a snapshot of the existing VM before replacing the disk and stores it in the staging location you specify. Existing disks connected to the VM are replaced with the selected restore point. The current VM must exist. **You can't use this option if the VM is deleted**.

---

## Q027:

Welche Wiederherstellungsart würden Sie auswählen, wenn Sie einen Datenträger einer bestehenden VM ersetzen möchten? 

- Neuen virtuellen Computer erstellen
- Datenträger wiederherstellen
- Vorhandene ersetzen

Which restore type should you select if you want to replace a disk on an existing virtual machine? 

- Create a new VM
- Restore disk
- Replace existing

---

### Answer:
- Vorhandene ersetzen
- Replace existing

Bei Wahl dieser Option kann ein Datenträger wiederhergestellt und dann verwendet werden, 
um einen Datenträger einer vorhandenen VM zu ersetzen.

Selecting this option allows for a disk to be restored and then used to replace a disk on an existing VM.

---

### References

---

# Answers that failed the assessment with corrections:

## Q026:

You have a Microsoft Entra tenant that contains a user named User1 and a group named Group1.

You need to enable User1 the ability to add members to Group1. Your solution should minimize administrative effort.

What should you do?

Select only one answer.

1. Add Group1 to new administrative unit and assign built-in Microsoft Entra role to User1

2. Assign custom Microsoft Entra role to User1

3. Modify Group1 owners

4. Modify Group1 properties

---

### Answer:

The correct answer is 4. Modify Group1 properties.

Specifically, you should modify the Group1 properties to allow members to invite guests.

Here's why:

Self-Service Group Management: Microsoft Entra ID allows you to configure groups so that members can invite guests. This is the simplest way to allow users to add members to a group without requiring any special administrative roles or complex configurations.
Here's why the other options are not the best approach for minimizing administrative effort:

Add Group1 to new administrative unit and assign built-in Microsoft Entra role to User1: Administrative units are used to scope administrative permissions. While this would work, it's more complex than necessary for this simple requirement. It involves creating a new administrative unit and assigning a role, which is more administrative overhead than simply changing a group setting.
Assign custom Microsoft Entra role to User1: Creating custom roles is also more complex than necessary. It requires defining specific permissions, which adds administrative overhead.
Modify Group1 owners: Making User1 an owner of Group1 would grant them full control over the group, including the ability to delete it. This is more privilege than is required to simply add members.
Therefore, modifying the Group1 properties to enable member invitations is the most straightforward and least administratively intensive solution.

---

### References

---

## Q025:

You have an Azure subscription that contains a user named User1, a resource group named RG1, and a virtual machine named VM1.

You enable a system-assigned managed identity for VM1.

To which identities can you assign the Reports Reader role?

Select only one answer.

1. User1 and RG1 only

2. User1 and VM1 only

3. User1 only

4. User1, RG1, and VM1

---

### Answer:

The correct answer is 2. User1 and VM1 only.

This is incorrect, the correct answer is VM1 only.

When you enable a system-assigned managed identity for VM1, Azure creates an identity specifically for VM1 in Azure Active Directory (now Microsoft Entra ID). This identity is tied to the VM's lifecycle.

You then assign roles (like Reports Reader) to this VM identity. You don't assign roles to the user (User1) or the resource group (RG1) in this context. The managed identity is the entity that gets the permissions.

Therefore, you can only assign the Reports Reader role to the managed identity of VM1.

---

### References

---

## Q024:

You have a Microsoft Entra tenant that contains the following users:

- User1 has a Department set to Sales and a Country set to USA

- User2 has a Department set to Marketing and a Country set to USA

- User3 has a Department set to Sales and a Country set to DE

- User4 has a Department set to Marketing and a Country set to DE

You create a group named Group1 that has the following dynamic membership rule.


`user.country -eq "USA" -and user.department -eq "Marketing" -or user.department -eq "Sales"`


Which users are members of Group1?

Select only one answer.

- User1 and User2 only

- User1 and User3 only

- User2 and User3 only

- User1, User2, and User3 only

- User1, User2, User3 and User4

---

### Answer:

The correct answer is User1, User2, and User3 only.

Let's break down the logic of the dynamic membership rule and evaluate it for each user:

Dynamic Membership Rule:

user.country -eq "USA" -and user.department -eq "Marketing" -or user.department -eq "Sales"
This rule translates to:

The user's country must be equal to "USA" AND the user's department must be equal to "Marketing" OR the user's department must be equal to "Sales".
User Evaluation:

User1: Country (USA) matches, department (Sales) matches OR department (Sales) matches. User qualifies.
User2: Country (USA) matches, department (Marketing) matches AND department (Marketing) matches (redundant). User qualifies.
User3: Country (DE) does not match, so the rule is not met. User does not qualify.
User4: Country (DE) does not match, so the rule is not met. User does not qualify.
Therefore, based on the rule and user attributes, User1, User2, and User3 are members of Group1. User4 is not a member.

---

### References

---

## Q023:

You have an Azure subscription.

You plan to run a data warehouse in an Azure virtual machine named VM1.

You need to ensure that VM1 is optimized for running a data warehouse.

Which VM type should you use for VM1?

Select only one answer.

- Compute optimized (F-Series)

- General purpose (D-Series)

- High performance computing (H-Series)

- Memory optimized (M-Series)

- Storage optimized (Ls-Series)

---

### Answer:

The correct answer is Memory optimized (M-Series).

Data warehouses are typically characterized by large datasets and complex queries that require significant memory for efficient processing. Memory-optimized VMs (M-series) are designed for these types of workloads. They offer a high memory-to-core ratio, making them ideal for:

Relational database servers
Large caches
In-memory analytics
Data warehousing
Here's why the other options are not the best fit:

Compute optimized (F-Series): These VMs are designed for compute-intensive applications, such as batch processing and web servers. While compute is important, memory is the primary bottleneck for many data warehouse workloads.
General purpose (D-Series): These VMs offer a balanced ratio of CPU, memory, and disk. They are suitable for a wide range of workloads but are not specifically optimized for the memory demands of a data warehouse.
High performance computing (H-Series): These VMs are designed for high-performance computing scenarios, such as simulations and complex scientific calculations. They are not typically required for standard data warehouse workloads.
Storage optimized (Ls-Series): These VMs are optimized for workloads that require high disk throughput and IOPS. While storage performance is important for data warehouses, memory is usually the primary performance bottleneck.

---

### References

---

## Q022:

Your company has an Azure subscription.

You plan to create a virtual machine scale set named VMSS1 that has the following settings:

- Resource group name: RG1
- Region: West US
- Orchestration mode: Uniform
- Security type: Standard
- OS disk type: SSD standard
- Key management: Platform-managed key

You need to add custom virtual machines to VMSS1.

What setting should you modify?

Select only one answer.

- Key management
- Orchestration mode
- OS disk type
- Security type

---

### Answer 2:
- Orchestration mode 
as long as you do it before deployeing!

> can I change the Orchestration mode of a scale set after I have deployed it?


ChatGPT said:
No, you cannot change the orchestration mode of a Virtual Machine Scale Set (VMSS) after deployment. 

Key Facts About Orchestration Modes:
- Uniform Mode: Fully automated scaling, does not allow manual VM additions.
- Flexible Mode: Allows manual VM additions and greater control.

---

### Answer 1:

The correct answer is Orchestration mode.

Here's why:

> Uniform Orchestration Mode: 

In Uniform mode, all virtual machine instances within the scale set are created from the same virtual machine model
(image, configuration, etc.). This means you can't add custom virtual machines directly.

> Flexible Orchestration Mode: 
Flexible orchestration mode allows you to create and manage virtual machine instances with different configurations within the same scale set. 
This enables scenarios where you need some level of customization for individual VMs.

Therefore, to add custom virtual machines to VMSS1, you must change the orchestration mode from Uniform to Flexible.

---

### References


---

## Q021:

You have an Azure subscription and an availability set named AS1 that has 5 update domains.

You deploy 27 virtual machines to AS1.

During a planned update, what is the minimum number of virtual machines that are available?

Select only one answer.

- 14

- 20

- 21

- 22

- 26

---

### Answer:

The correct answer is 22.

Here's why:

Availability sets use update domains to ensure that not all virtual machines are rebooted simultaneously during planned maintenance.

VMs per Update Domain: With 27 VMs and 5 update domains, the VMs are distributed as evenly as possible across the update domains. In this case, 27 / 5 = 5 with a remainder of 2. This means 3 update domains will have 6 VMs each, and 2 update domains will have 5 VMs each.

Minimum Availability: During an update, only one update domain is updated at a time. Therefore, in the worst-case scenario (the update domain with 6 VMs is being updated), 6 VMs will be unavailable.

Calculation: 27 total VMs - 5 VMs in the update domain being updated = 22 available VMs.

Therefore, the minimum number of available virtual machines during a planned update is 22.

---

### References

---

## Q020:

You have an Azure subscription.

You need to deploy a virtual machine that runs Windows Server 2022 Datacenter: Azure Edition.

Which security type can you select when deploying virtual machine?

Select only one answer.

- Standard only

- Standard or trusted launch only

- Standard, trusted launch or confidential

- Trusted launch or confidential only

---

### Answer:

The correct answer is Standard, trusted launch or confidential.

Azure offers three main security types for virtual machines:

Standard: This is the baseline security offering and is available for most VM sizes and operating systems.
Trusted launch: This offers enhanced security by protecting against boot kits and rootkits. It uses features like Secure Boot, vTPM, and boot integrity monitoring.
Confidential VMs: These offer the highest level of security by encrypting the VM's memory while in use, protecting data even if the hypervisor is compromised. This uses hardware-based Trusted Execution Environments (TEEs).
Windows Server 2022 Datacenter: Azure Edition supports all three of these security types: Standard, Trusted launch, and Confidential VMs.

---

### References

---

## Q019:

You have the following Azure resources:

1. a virtual machine named VM1
2. a Recovery Services vault named Vault1

On January 1, you configure backups for VM1 by using the following backup policy:

- Frequency: Daily

- Time: 23:00

- Timezone: (UTC) Coordinated Universal Time

- Retain instant recovery snapshot(s) for: 2 Day(s)

- Retention of daily backup point: 7 Day(s)

- Azure Backup Resource Group: Backup1RG

How many restore point collections recovery points will be stored in Backup1RG on January 10?

Select only one answer.

- 2

- 7

- 9

- 10

---

### Answer:

The correct answer is 9.

Here's why:

Daily Backups: From January 1 to January 10, there are 10 days, meaning 10 daily backups are created.
Retention of Daily Backups: The policy retains daily backups for 7 days. On January 10, you'll have the backups from January 3 to January 9 (7 days). The backups from January 1 and 2 will have been deleted due to the 7-day retention policy.
Instant Recovery Snapshots: The policy retains instant recovery snapshots for 2 days. On January 10, you'll have the snapshots from January 8 and 9.
Therefore, you will have 7 daily backup recovery points + 2 instant recovery snapshot recovery points = 9 restore point collections recovery points in Backup1RG on January 10.

---

### References

---

## Q018:

Your company’s Azure subscription contains an Azure virtual machine.

You need to back up the virtual machine every 12 hours.

What should you create first?

Select only one answer.

- a backup policy in a backup vault

- a standard backup policy in a recovery services vault

- an enhanced backup policy in a recovery services vault

---

### Answer 2:

Correct Answer:
An enhanced backup policy in a Recovery Services vault

Explanation:
Azure Backup allows you to schedule backups at different intervals, but the backup policy type determines the backup frequency.

Backup Policy Types:

> Standard Backup Policy (Classic)

Supports only daily backups (once every 24 hours).
Does not meet the requirement of backing up every 12 hours.

> Enhanced Backup Policy 

Supports multiple backups per day (as frequent as every 4 hours).
Allows higher backup frequency, which meets the requirement of every 12 hours.

> Why Not the Other Options?
A backup policy in a backup vault: 
Incorrect terminology: Azure VM backups use a Recovery Services Vault, not a "backup vault".

A standard backup policy in a Recovery Services Vault:
Standard policies only support daily backups, but not every 12 hours.

> Conclusion:
To back up an Azure VM every 12 hours, you need:
An enhanced backup policy in a Recovery Services vault.

---

### Answer 1:

The correct answer is a standard backup policy in a recovery services vault.

Here's why:

Recovery Services Vault: Backups in Azure are managed through Recovery Services vaults. You must have a Recovery Services vault before you can create backup policies or back up resources.
Backup Policies: Backup policies define the backup schedule (frequency, time of day) and retention range (how long backups are kept). These policies are created within a Recovery Services vault.
Standard vs Enhanced: Enhanced policies offer features like hourly backups and are generally used for SQL server workloads. For a general VM backup with a 12-hour frequency, a standard policy within a Recovery Services vault is sufficient and the correct first step.
Therefore, you must first create a Recovery Services vault, and then create a standard backup policy within it to define the 12-hour backup schedule.

---

### References

[Back up an Azure VM using Enhanced policy](https://learn.microsoft.com/en-us/azure/backup/backup-azure-vms-enhanced-policy?tabs=azure-portal)    

Azure Backup now supports Enhanced policy for Azure VM backup that offers:

- Zonal resiliency using Zone-redundant storage (ZRS) for Instant Restore snapshots.
- Multiple Backups per Days. You can schedule backups as frequently as every 4 hours for Azure VMs.
- Support for new Azure offerings including Trusted Launch virtual machines, Premium SSD v2 and Ultra SSD disks, multi-disk crash consistent snapshot support.
- Longer retention in snapshot (operational) tier up to 30 days.

[Back up Azure VMs in a Recovery Services vault](https://learn.microsoft.com/en-us/azure/backup/backup-azure-arm-vms-prepare)    

Assign a Backup policy.

The default policy backs up the VM once a day. 
The daily backups are retained for 30 days. 
Instant recovery snapshots are retained for two days.

If you don't want to use the default policy, select Create New, and create a custom policy as described in the next procedure.

[Create a custom policy](https://learn.microsoft.com/en-us/azure/backup/quick-backup-vm-portal#create-a-custom-policy)  

> In Backup schedule: 
specify when backups should be taken. You can take daily or weekly backups for Azure VMs !

---

## Q017:

You have an Azure subscription that contains an Azure disk named Disk1.

You plan to use an Azure Backup to backup Disk1.

What should you deploy first?

Select only one answer.

- a Backup vault

- a Storage account

- a Recovery Services vault

- an Azure Backup Server

---

### Answer 1:

The correct answer is a Recovery Services vault.

Azure Backup uses Recovery Services vaults to store backups and manage backup policies. Before you can back up any resource, including Azure disks, you must create a Recovery Services vault.

Here's why the other options are incorrect:

A Backup vault: There is no resource called "Backup vault" in Azure. The correct term is "Recovery Services vault".
A Storage account: While backups are stored in storage accounts managed by Azure Backup, you don't create the storage account directly. The Recovery Services vault manages the underlying storage.
An Azure Backup Server: Azure Backup Server is an on-premises solution for backing up on-premises data to Azure. It's not required for backing up Azure resources like disks.
Therefore, creating a Recovery Services vault is the first step in backing up Disk1.

---

### References

[what is difference between Recovery Services vault and backup vault](https://learn.microsoft.com/en-us/answers/questions/405915/what-is-difference-between-recovery-services-vault)  
[Azure Backup Vault vs Recovery Services Vault](https://stackoverflow.com/questions/67556611/azure-backup-vault-vs-recovery-services-vault)  

"Recovery Services vault" was there first.
https://learn.microsoft.com/en-us/azure/backup/backup-azure-recovery-services-vault-overview

It can back up:

VMs (via a backup extension)
File Shares (part of storage account)
SQL Server / SAP HANA databases, when deployed on an Azure VM


"Backup vault" came later.
https://learn.microsoft.com/en-us/azure/backup/backup-vault-overview

It can back up:

Managed disks (reads the disk directly, does not use VM extension)
Blobs (part of storage account)
Azure PostgreSQL databases
Notice the absence of regular SQL Server (Azure PaaS) databases: those backups are kept with the SQL Server resource itself, they are not sent to a Recovery Services or Backup vault.

---

## Q016:

You have a Recovery Services vault named Recovery1 that includes a backup policy named Policy1.

You back up several Azure virtual machines to Recovery1 by using Policy1.

You need to view the Azure Backup reports.

What should you do first?

Select only one answer.

- Configure the Diagnostics settings of Recovery1.

- Create an Azure Log Analytics workspace.

- Modify the Backup Configuration settings of Recovery1.

---

### Answer:

The correct answer is Configure the Diagnostics settings of Recovery1.

Azure Backup reports rely on diagnostic logs. To view these reports, you must first configure Recovery Services vault's diagnostic settings to send data to a Log Analytics workspace (or a storage account or Event Hub, but Log Analytics is the standard for reporting). The reports themselves are then viewed within the Log Analytics workspace.

The other options are incorrect:

Create an Azure Log Analytics workspace: While a Log Analytics workspace is required to view the reports, you first need to configure Recovery1 to send its diagnostic data there. Creating the workspace beforehand doesn't automatically enable data collection.
Modify the Backup Configuration settings of Recovery1: Backup configuration settings relate to the backup process itself (e.g., backup schedule, retention range), not to reporting.
Therefore, configuring the diagnostic settings is the first step.

---

### References

---

## Q015:

You have an Azure network security group (NSG) named NSG1 that is associated to a virtual network subnet named Subnet1. NSG1 has the following inbound security rules:

1. Rule1 has a priority of 100 and allows port 3389 on TCP protocol from any source and to any destination

2. Rule2 has a priority of 200 and allows ports 80 and 8080 on UDP protocol from any source and to any destination

3. Rule3 has a priority of 300 and denies ports 1-2000 on TCP protocol from any source and to any destination

4. Rule4 has a priority of 400 and allows ports 50-500 on TCP protocol from VirtualNetwork source and to any destination

5. Rule5 has a priority of 500 and allows ports 80 and 443 on TCP protocol from any source and to any destination

You need to allow http and https connections from the internet to Subnet1.

What should you change for NSG1?

Select only one answer.

- Priority for Rule3 to 450

- Priority for Rule4 to 250

- Priority for Rule5 to 250

- Protocol for Rule2 to TCP

---

### Answer:

The correct answer is Priority for Rule5 to 250.

Here's why:

You want to allow HTTP (port 80) and HTTPS (port 443) from the internet. Rule5 already allows this.
NSG rules are processed in order of priority, from lowest to highest. A lower number means higher priority.
Currently, Rule3 (deny TCP ports 1-2000) has a higher priority (300) than Rule5 (allow TCP ports 80 and 443, priority 500). This means Rule3 is evaluated first, and it blocks ports 80 and 443 before Rule5 even gets a chance to allow them.
By changing the priority of Rule5 to 250, it becomes higher in priority than Rule3. Now, the allow rule for ports 80 and 443 is evaluated before the deny rule, effectively allowing HTTP and HTTPS traffic from the internet.

The other options are incorrect:

Priority for Rule3 to 450: This would make the deny rule lower priority, but Rule5 is already allowing the required ports, so this change wouldn't be effective.
Priority for Rule4 to 250: Rule4 allows traffic only from the VirtualNetwork source. This wouldn't allow traffic from the internet.
Protocol for Rule2 to TCP: Rule2 allows UDP traffic. Changing the protocol won't affect the TCP ports 80 and 443 that you need to allow.

---

### References

---

## Q014:

You have an Azure subscription that contains a virtual network named VNET1. 
VNET1 uses the following address spaces:

- 10.10.1.0/24
- 10.10.2.0/28

VNET1 contains the following subnets:

- Subnet1- has an address space of 10.10.1.0/24
- Subnet2- has an address space of 10.10.2.0/28

To Subnet1, you deploy a virtual machine named VM1 that runs Windows Server. 
VM1 has Remote Desktop enabled.

VM1 does NOT have a public IP address.

You need to be able to deploy Azure Bastion to protect VM1.

What should you do first?

Select only one answer.

- Add a new subnet to VNET1.

- Add a public IP address to VM1.

- Add an extension to VM1.

- Modify the address space of VNET1.

---

### Answer 2:

Correct Answer:
Add a new subnet to VNET1.

Explanation:
Azure Bastion requires a dedicated subnet named AzureBastionSubnet with a minimum /27 address space.

Current VNet and Subnets:
VNET1 Address Spaces:
10.10.1.0/24 (Used by Subnet1)
10.10.2.0/28 (Used by Subnet2)
Subnet1 (10.10.1.0/24) Used for VM1.
Subnet2 (10.10.2.0/28) Too small for Bastion (/28 supports only 16 addresses).

Why Other Options Are Incorrect:
Add a public IP address to VM1 
Bastion is designed to eliminate the need for public IPs.

Add an extension to VM1
Bastion is a network service, not an extension that runs on a VM.

Modify the address space of VNET1
Not necessary unless there's no available space for a new /27 subnet.

Solution:
Create a new subnet named AzureBastionSubnet
Assign it a minimum of /27 address space (e.g., 10.10.3.0/27, if space is available).
Thus, the first step is to add a new subnet to VNET1.

---

### Answer 1:

The correct answer is Add a new subnet to VNET1.

Azure Bastion requires a dedicated subnet named AzureBastionSubnet. This subnet must have an address space of at least /26. You cannot deploy Bastion to an existing subnet that also hosts other resources.

Here's why the other options are incorrect:

Add a public IP address to VM1: Bastion's purpose is to avoid the need for VMs to have public IP addresses. Adding one defeats the purpose.
Add an extension to VM1: Extensions are software components that provide post-deployment configuration and automation tasks on Azure VMs. They are not related to Bastion deployment.
Modify the address space of VNET1: While it's possible the existing address space might not have enough available addresses for a /26 subnet, the first step is to create the subnet. You don't need to change the entire VNet's address space unless there are absolutely no available address ranges left. In this case, there is a /28 subnet that is not fully utilized, so there is room to create the required /26 subnet.
Therefore, creating the AzureBastionSubnet is the first and necessary step.

---

### References

[Azure Bastion subnet](https://learn.microsoft.com/en-us/azure/bastion/configuration-settings#subnet) 

For Azure Bastion resources deployed on or after November 2, 2021, the minimum AzureBastionSubnet size is /26 or larger (/25, /24, etc.). All Azure Bastion resources deployed in subnets of size /27 prior to this date are unaffected by this change and will continue to work, but we highly recommend increasing the size of any existing AzureBastionSubnet to /26 in case you choose to take advantage of host scaling in the future.

---

## Q013:

You have an Azure subscription that contains a storage account named storage1 and the following virtual machines:

1. VM1 has a public IP address of 13.68.158.24 and is connected to VNET1/Subnet1
2. VM2 has a public IP address of 52.255.145.76 and is connected to VNET1/Subnet1
3. VM3 has a public IP address of 13.68.158.50 and is connected to VNET1/Subnet2

The subnets have the following service endpoints:

- Subnet1 has a Microsoft.Storage service endpoint
- Subnet2 does NOT have any service endpoint

Storage1 has a firewall configured to allow access from the 13.68.158.0/24 IP address range only.

Which virtual machines can access storage1.

Select only one answer.

- VM1 and VM2 only

- VM1 and VM3 only

- VM1 only

- VM1, VM2, and VM3

- VM3 only

---

### Answer:

The VMs that can access storage1 are:

VM1 only
Here's why:

Storage Firewall Restriction: Storage1's firewall only allows access from the 13.68.158.0/24 IP address range.

VM IP Addresses:

VM1: 13.68.158.24 - Falls within the allowed range.
VM2: 52.255.145.76 - Falls outside the allowed range.
VM3: 13.68.158.50 - Falls within the allowed range.
Service Endpoints:

Subnet1 where VM1 and VM2 reside has a service endpoint for Microsoft Storage. This service endpoint allows VMs in Subnet1 to bypass the firewall restrictions as long as they use the Azure internal network. However, the scenario specifies that VMs must use their public IP addresses, so the service endpoint isn't relevant in this case.
Subnet2 where VM3 resides does not have a service endpoint for Microsoft Storage.
Therefore, considering both the storage firewall restriction and the requirement to use public IP addresses, only VM1 with a public IP falling within the allowed range can access storage1.

---

### References

---

## Q012:

You have an Azure subscription that contains a virtual machine named VM1 and a storage account named storage1.

You need to ensure that VM1 can access storage1 by using the Azure backbone.

What should you configure?

Select only one answer.

- a routing table

- a service endpoint

- a VPN gateway

- Peering

---

### Answer:

The correct answer is a service endpoint.

Here's why:

Service Endpoints: Service endpoints provide secure and direct connectivity to Azure services (like Storage) from within a virtual network, using the Azure backbone network. This avoids traversing the public internet. This is the most direct and efficient method for VM1 to access storage1 using the Azure backbone.
Routing Table: Routing tables control how network traffic is routed within a virtual network. While you could use a routing table to direct traffic to a Network Virtual Appliance (NVA) that then connects to storage, this is more complex and not necessary when service endpoints are available.
VPN Gateway: A VPN gateway creates a secure connection between an on-premises network and an Azure virtual network. This is not needed for communication between a VM and a storage account within the same Azure environment.
Peering: VNet peering connects two virtual networks together. This is useful for connecting different virtual networks within Azure, but it's not required for a VM to access a storage account in the same subscription.
Therefore, configuring a service endpoint for Storage on the subnet where VM1 resides is the correct and most efficient solution.

---

### References

---


## Q011:

You have an Azure Storage account named storage1.

You create the following encryption scopes for storage1:

1. Scope1 that has an encryption type of Microsoft-managed keys
2. Scope2 that has an encryption type of Customer-managed keys

Which storage services can be used with Scope2?

Select only one answer.

- blob and file only

- blob, file, table, and queue

- blob only

- file only

- table and queue only

---

### Answer:

The correct answer is blob only.

Customer-managed keys (CMK) for encryption scopes are currently only supported for block blobs within Azure Blob Storage. They are not supported for other storage services like files, tables, or queues.

Therefore, only blob storage can be used with Scope2 (the customer-managed key scope).

---

### References

---

## Q010:

You have an Azure Storage account named storage1 that is configured to use the Hot access tier.

Storage1 has a container named container1 and the lifecycle management rule with following settings:

- Move blob to cool storage: Selected > Days after last modification: 3

- Move blob to archive storage: Selected > Days after last modification: 5

On December 1, you create a file named File1 in container1.
On December 10, you rehydrate File1 and move the file to the Hot access tier.

When will File1 be moved to archive storage?

Select only one answer.

- on December 15

- on December 18

- on January 1

- within 24 hours

---

### Answer:

The correct answer is on December 15.

Here's why:

The lifecycle management rule is based on the last modification time.

1. File1 was created on December 1.
2. It was rehydrated (and moved back to hot) on December 10. This modifies the file, resetting the lifecycle timer.
3. The rule specifies moving to archive after 5 days after last modification.
4. 5 days after December 10 is December 15.

Therefore, File1 will be moved to archive storage on December 15.

---

### References

---

## Q009:

You have an Azure subscription that contains the following storage accounts:

1. storage1, configured as StorageV2 kind

2.  storage2, configured as BlobStorage kind

3. storage3, configured as FileStorage kind

Which storage account or storage accounts can you use Lifecycle management?

Select only one answer.

- storage1 and storage2 only

- storage1 and storage3 only

- storage1 only

- Storage1, storage2 and storage3

- storage2 and storage3 only

---

### Answer 2:

Correct Answer:
storage1 and storage2 only

Explanation:
Azure Lifecycle Management applies only to Blob Storage (block & append blobs) and General-purpose v2 (StorageV2) accounts.

Storage Account Types and Lifecycle Management Support:

storage1 (StorageV2 kind) Supported
Supports lifecycle management for blobs.

storage2 (BlobStorage kind) Supported
Specifically designed for blob storage and supports lifecycle policies.

storage3 (FileStorage kind) Not Supported
Lifecycle management does not apply to Azure Files, only blobs.

Eliminating Incorrect Options:
storage1 and storage3 only (storage3 does not support lifecycle management).
storage1 only (storage2 also supports lifecycle management).
storage1, storage2, and storage3 (storage3 is not supported).
storage2 and storage3 only (storage3 is not supported).

Thus, the correct answer is: storage1 and storage2 only.

---

### Answer 1:

The correct answer is C storage1 only.

Lifecycle Management policies in Azure are available for:

General Purpose v2 (StorageV2) accounts: This is the recommended storage account type for most scenarios and supports all lifecycle management features.
Block Blob Storage accounts: These are a specialized type of StorageV2 account.
BlobStorage accounts (the older Blob-only accounts) and FileStorage accounts do not support lifecycle management policies.

Therefore, only storage1 (StorageV2) can use lifecycle management.

---

### References


---

## Q008:

You have an Azure storage account that contains a blob container named container1.

You need to configure access to container1.

Which authorization types can you use?

Select only one answer.

- Microsoft Entra ID only

- Microsoft Entra ID, shared access signature or certificate only

- Microsoft Entra ID, storage key or shared access signature only

- Microsoft Entra ID, storage key, shared access signature or certificate

- Storage key or shared access signature only

---

### Answer 2:

Correct Answer: 
Microsoft Entra ID, storage key, or shared access signature only

Explanation:
Azure Storage supports multiple authentication methods for accessing Blob Storage (container1):

Microsoft Entra ID (formerly Azure AD) (For role-based access control (RBAC) authentication)
Storage key (Using the storage account’s access keys)
Shared Access Signature (SAS) (A time-limited token for controlled access)
Certificates Not Supported (Azure Storage does not support certificate-based authentication)

Eliminating Incorrect Options:
Microsoft Entra ID only: Incorrect because storage key and SAS are also valid.
Microsoft Entra ID, shared access signature, or certificate only: Incorrect because storage key is missing, and certificate is not supported.
Microsoft Entra ID, storage key, shared access signature, or certificate: Incorrect because certificate is not supported.
Storage key or shared access signature only:  Incorrect because Microsoft Entra ID is also supported.

Thus, the correct answer is:
Microsoft Entra ID, storage key, or shared access signature only.

---

### Answer 1:

The correct answer is Microsoft Entra ID, storage key, shared access signature only.

Here's a breakdown of the authorization methods for Azure Blob Storage:

Microsoft Entra ID (Azure AD): Use Azure AD to authenticate users and applications using role-based access control (RBAC). This is the recommended approach for most scenarios, especially in enterprise environments.
Storage Account Keys: There are two storage account access keys. They grant full access to all data in the storage account. Using storage account keys should be avoided whenever possible due to their broad permissions.
Shared Access Signatures (SAS): SAS tokens provide granular, time-bound access to specific storage resources. You can create SAS tokens at the container, blob, or even directory level, granting specific permissions (read, write, delete, etc.).
Certificates are not a direct method for authorizing access to Azure Blob storage. While certificates can be used for authentication in other Azure services, they are not used in this context.

---

### References

---

## Q007:

You have an Azure container registry that stores an image named Image1 and a Windows Server 2022 Azure virtual machine named VM1.

You need to ensure that you can run Image1 in VM1.

What should you install in VM1?

Select only one answer.

- Azure Portal

- Docker

- Hyper-V role

- .NET Framework 4.8

---

### Answer:

The correct answer is Docker.

Here's why:

Docker: Docker is the container runtime environment. To run Docker images (like Image1), you need to have Docker installed on the host (in this case, VM1).
Azure Portal: The Azure portal is a web-based management interface for Azure services. It's not something you install on a VM to run containers.
Hyper-V role: Hyper-V is Microsoft's hypervisor for creating and managing virtual machines. While Docker can use Hyper-V as a backend on Windows, simply installing Hyper-V is not enough to run Docker containers. You still need the Docker runtime itself. Docker Desktop for Windows uses Hyper-V by default, but Docker Engine can also run on Windows Server without Hyper-V using process isolation.
.NET Framework 4.8: The .NET Framework is a software framework for developing and running applications on Windows. It's not directly related to running Docker containers.
Therefore, to run the Docker image Image1 on VM1, you must install Docker on VM1.

---

### References

--

## Q006:

You have Azure subscription that includes virtual network named VNet1 in West US region.

You plan to deploy following container instances:

instance1, running Windows container image in West US region

instance2, running Linux container image in West US region

instance3, running Windows container image in East US region

Which container instances can be deployed to VNet1?

Select only one answer.

- instance1 and instance2 only

- instance1 and instance3 only

- instance1, instance2 and instance3

- instance1 only

- instance2 only

---

### Answer 2:

Answer:
instance1 and instance2 only

Explanation:
Azure Container Instances (ACI) can be deployed into a virtual network (VNet) only if they are in the same region as the VNet.

instance1 (Windows, West US)  Allowed (Same region as VNet1)
instance2 (Linux, West US)  Allowed (Same region as VNet1)
instance3 (Windows, East US)  Not Allowed (Different region from VNet1)
Since instance3 is in East US and VNet1 is in West US, it cannot be deployed to VNet1.

[How to deploy Azure Container Instance to VNET using Azure CLI](https://stackoverflow.com/questions/61383415/how-to-deploy-azure-container-instance-to-vnet-using-azure-cli)  

You should deploy the container instance in the region that is the same as the Vnet in the region.

---

### Answer 1:


The correct answer is instance1 and instance2 only.

Azure Container Instances (ACI) must reside in the same region as the virtual network they are integrated with. VNet1 is in West US. Therefore, only the container instances also in West US (instance1 and instance2) can be deployed to VNet1. Instance3 is in East US, so it cannot be deployed to VNet1. The operating system of the container (Windows or Linux) doesn't affect the VNet integration requirement.

---

### References

---

## Q005:

You plan to create an Azure container instance named container1 that will use a Docker image named Image1.

You need to ensure that container1 has persistent storage.

Which Azure resources should you deploy for the persistent storage?

Select only one answer.

- an Azure container registry

- an Azure SQL database

- an Azure Storage account and a blob container

- an Azure Storage account and a file share

---

### Answer:

The correct answer is an Azure Storage account and a file share.

Here's why:

Azure Container Registry (ACR): Stores Docker images. It does not provide persistent storage for running containers.
Azure SQL Database: A relational database service. While it can store data, it's not the appropriate solution for providing persistent storage directly to a container instance in the way a file system would be used.
Azure Storage account and a blob container: Blob storage is suitable for storing large amounts of unstructured data, but it's not directly mountable as a file system within a container instance in the same way a file share is.
Azure Storage account and a file share: Azure File shares provide a fully managed file share in the cloud that can be mounted as a network drive within a container instance. This is the correct solution for providing persistent storage to Azure Container Instances.\

---

### References

---

## Q004:

You have an Azure web app named WebApp1.

You discover that backup options are unavailable for WebApp1.

You need to back up WebApp1.

What should you do first?

Select only one answer.

- Modify the Application settings of WebApp1.

- Modify the platform settings of WebApp1.

- Scale out the app service plan.

- Scale up the app service plan.

---

### Answer:

The correct answer is Scale up the app service plan.

Backups for Azure Web Apps are only available in the Standard, Premium, PremiumV2, PremiumV3, and Isolated App Service Plan tiers. If your web app is running in a lower tier (like Free or Shared), the backup functionality will be unavailable. Therefore, the first step is to scale up the App Service Plan to a supported tier.

---

### References

---

## Q003:

You have an Azure web service named Contoso2022 that runs in the Standard App Service plan. Contoso2022 has five deployment slots in use.

A user named User1 has the Contributor role for Contoso2022.

You need to ensure that User1 can create additional deployment slots to Contoso2022.

What should you do?

Select only one answer.

- Assign User1 the Owner role for Contoso2022.

- Assign User1 the Website Contributor role for Contoso2022.

- Scale out the Contoso2022 App Service plan.

- Scale up the Contoso2022 App Service plan.

---

### Answer:

The correct answer is Scale up the Contoso2022 App Service plan.

Here's why:

The number of deployment slots available for an App Service is directly tied to the App Service Plan's tier. Standard tier plans allow for 5 deployment slots. To have more than 5 deployment slots, you must upgrade to a Premium tier plan. User permissions (Contributor, Owner, Website Contributor) control who can manage deployments, but they do not increase the number of available slots. Only scaling up to a higher tier will increase the limit.

---

### References

---

## Q002:

You have an Azure subscription that includes a virtual network named VNet1.

You plan to create a web app named WebApp1 and deploy it to VNet1.

You need to prepare the environment for the planned web app. The solution must minimize costs.

Which app service plan size should you use?

Select only one answer.

- Dev / Test B1

- Dev / Test F1

- Isolated I1V2

- Production P1V2

- Production P3V3

---

### Answer:

The correct answer is Dev / Test B1.

Here's why:

Integration with VNet: To integrate a web app with an Azure Virtual Network (VNet), you need an App Service Plan in the Basic tier or higher (Standard, Premium, Isolated). The Free (F1) and Shared tiers do not support VNet integration.
Cost Minimization: The B1 tier is the lowest cost tier that supports VNet integration.
Therefore, to minimize costs while achieving the requirement of deploying the web app to VNet1, the Dev/Test B1 App Service Plan size is the most appropriate choice.

---

### References

---

## Q001:

You plan to deploy the following Azure web apps:

1. WebApp1, that uses the .NET 8 runtime stack
2. WebApp2, that uses the ASP.NET V4.8 runtime stack
3. WebApp3, that uses the Java 21 runtime stack
4. WebApp4, that uses the PHP 8.3 runtime stack

You need to create the app service plans for the web apps.

What is the minimum number of app service plans that should be created?

---

### Answer:

The minimum number of app service plans you need to create is one.

Here's why:

Windows Compatibility: .NET 8, ASP.NET V4.8, and PHP 8.3 are all supported on the Windows platform in Azure App Service.
Java Compatibility: While Java is not natively supported on Windows, Azure App Service offers a Linux option specifically for Java applications.
Therefore, you can create a single App Service plan with a Windows operating system to host WebApp1, WebApp2, and WebApp4. WebApp3, being a Java application, can be deployed to the same App Service plan but will require a Linux worker tier within the plan.

This approach allows you to minimize costs by using a single plan and leverage the platform's flexibility to accommodate different runtime stacks within the same plan.

---

### References

---